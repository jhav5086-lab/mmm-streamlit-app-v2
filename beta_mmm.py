# -*- coding: utf-8 -*-
"""Beta_MMM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14klC7g67_QAaPRaWFD-MODrI2GzTqHA8
"""

# Commented out IPython magic to ensure Python compatibility.
# Marketing Mix Modeling - Colab Testing Version (Fixed)
import pandas as pd
import numpy as np
# import matplotlib.pyplot as plt # Commented out as not used for main plots
# import seaborn as sns # Commented out as not used for main plots
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Add other necessary imports
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import ElasticNet, Lasso, Ridge
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
from scipy.optimize import minimize
from statsmodels.tsa.seasonal import seasonal_decompose

# Plotly imports
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots # Import make_subplots
from IPython.display import display

# Set style for plots (not needed for Plotly)
# plt.style.use('default')
# sns.set_palette("husl")


# Function to convert Indian number format to float
def convert_indian_number(value):
    """Convert Indian number format string to float"""
    if isinstance(value, str):
        # Remove commas and strip whitespace
        cleaned_value = value.replace(',', '').strip()

        # Handle special cases like ' -   ' which should be treated as NaN
        if cleaned_value in ['-', ''] or cleaned_value.isspace():
            return np.nan

        try:
            return float(cleaned_value)
        except ValueError:
            print(f"Could not convert value: '{value}'")
            return np.nan
    return value

# Load and preprocess data
def load_and_preprocess_data(file_path):
    """Load and preprocess the marketing mix data"""
    # Load the data
    data = pd.read_csv(file_path)

    # First, identify all columns that might contain Indian number format
    # These are all columns except the date column
    all_columns = data.columns.tolist()
    date_column = 'Week_Ending'

    if date_column in all_columns:
        all_columns.remove(date_column)

    # Convert all numeric columns (including Sales)
    for col in all_columns:
        # Check if the column contains string values with commas (Indian number format)
        if data[col].dtype == 'object' and data[col].str.contains(',').any():
            data[col] = data[col].apply(convert_indian_number)
        # Also convert columns that might be objects but don't have commas (like ' - ')
        elif data[col].dtype == 'object':
             data[col] = data[col].apply(convert_indian_number)


    # Handle missing values in Paid Search Impressions
    if 'Paid Search Impressions' in data.columns:
        missing_count = data['Paid Search Impressions'].isna().sum()
        if missing_count > 0:
            print(f"Found {missing_count} missing values in 'Paid Search Impressions'. Imputing with 0.")
            data['Paid Search Impressions'] = data['Paid Search Impressions'].fillna(0)

    # Convert date column
    if 'Week_Ending' in data.columns:
        data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%d-%m-%Y %H:%M', errors='coerce')
        data = data.sort_values('Week_Ending').reset_index(drop=True)

    return data

# Format numbers in millions (not needed for Plotly tickformat)
# def format_millions(x, pos):
#     """Format numbers in millions for plot axes"""
#     return f'{x/1e6:.1f}M'


# Perform comprehensive EDA
def perform_comprehensive_eda(data, target_var='Sales'):
    """Perform comprehensive exploratory data analysis"""
    print("="*60)
    print("COMPREHENSIVE EXPLORATORY DATA ANALYSIS")
    print("="*60)

    # 1. Basic Information
    print("\n1. BASIC DATASET INFORMATION")
    print("="*40)
    print(f"Shape: {data.shape}")
    print(f"Columns: {list(data.columns)}")
    if 'Week_Ending' in data.columns:
        print(f"Date Range: {data['Week_Ending'].min()} to {data['Week_Ending'].max()}")
    print(f"Missing Values: {data.isnull().sum().sum()}")

    # Check if target variable is numeric - should be handled in load_and_preprocess_data now
    if data[target_var].dtype == 'object':
         print(f"\nWARNING: Target variable '{target_var}' is not numeric after preprocessing.")


    # 2. Summary Statistics
    print("\n\n2. SUMMARY STATISTICS")
    print("="*40)

    # Numeric variables summary
    numeric_df = data.select_dtypes(include=[np.number])
    print("Numeric Variables Summary:")
    display(numeric_df.describe())

    # Add skewness and kurtosis
    skewness = numeric_df.skew().to_frame('Skewness')
    kurtosis = numeric_df.kurtosis().to_frame('Kurtosis')
    stats_df = pd.concat([skewness, kurtosis], axis=1)
    print("\nSkewness and Kurtosis:")
    display(stats_df)

    # 3. Univariate Analysis
    print("\n\n3. UNIVARIATE ANALYSIS")
    print("="*40)

    # Create distribution plots for all numeric variables using Plotly
    numeric_cols = numeric_df.columns.tolist()
    for col in numeric_cols:
        fig = px.histogram(data, x=col, nbins=30, title=f"Distribution of {col}")
        fig.update_layout(
            xaxis_title=col,
            yaxis_title="Frequency",
            bargap=0.1 # Add gap between bars
        )
        # Add vertical lines for mean and median
        mean_val = data[col].mean()
        median_val = data[col].median()
        fig.add_vline(x=mean_val, line_dash="dash", line_color="red", annotation_text=f"Mean: {mean_val:.2f}", annotation_position="top right")
        fig.add_vline(x=median_val, line_dash="dash", line_color="green", annotation_text=f"Median: {median_val:.2f}", annotation_position="top left")

        fig.show()


    # 4. Bivariate Analysis
    print("\n\n4. BIVARIATE ANALYSIS: RELATIONSHIP WITH TARGET VARIABLE")
    print("="*40)

    # Create scatter plots against target variable using Plotly
    if target_var in numeric_cols:
        numeric_cols_for_scatter = numeric_cols.copy()
        numeric_cols_for_scatter.remove(target_var)

    for col in numeric_cols_for_scatter:
        fig = px.scatter(data, x=col, y=target_var, title=f"{target_var} vs {col}")
        fig.update_layout(
            xaxis_title=col,
            yaxis_title=target_var
        )
        # Add correlation coefficient
        correlation = data[col].corr(data[target_var])
        fig.add_annotation(
            x=data[col].min() + (data[col].max() - data[col].min()) * 0.05,
            y=data[target_var].max() - (data[target_var].max() - data[target_var].min()) * 0.05,
            text=f"r = {correlation:.3f}",
            showarrow=False,
            bgcolor="white",
            opacity=0.8
        )
        fig.show()


    # 5. Time Series Analysis
    print("\n\n5. TIME SERIES ANALYSIS")
    print("="*40)

    if 'Week_Ending' in data.columns:
        # Plot target variable over time using Plotly
        fig = px.line(data, x='Week_Ending', y=target_var, title=f"{target_var} Over Time (in Millions)")
        fig.update_layout(
            xaxis_title="Date",
            yaxis_title="Sales (in Millions)",
            yaxis_tickformat=".1s" # Format y-axis to show values in millions
        )
        fig.show()


        # Add seasonal decomposition using Plotly
        print("Seasonal Decomposition:")
        try:
            # Ensure the data is sorted by date and set as index
            temp_df = data.set_index('Week_Ending').sort_index()
            decomposition = seasonal_decompose(temp_df[target_var], period=4, model='additive', extrapolate_trend='freq')

            fig = make_subplots(rows=4, cols=1,
                                subplot_titles=('Observed', 'Trend', 'Seasonal', 'Residuals'),
                                shared_xaxes=True)

            fig.add_trace(go.Scatter(x=temp_df.index, y=decomposition.observed, mode='lines', name='Observed'), row=1, col=1)
            fig.add_trace(go.Scatter(x=temp_df.index, y=decomposition.trend, mode='lines', name='Trend'), row=2, col=1)
            fig.add_trace(go.Scatter(x=temp_df.index, y=decomposition.seasonal, mode='lines', name='Seasonal'), row=3, col=1)
            fig.add_trace(go.Scatter(x=temp_df.index, y=decomposition.resid, mode='lines', name='Residuals'), row=4, col=1)


            fig.update_layout(height=800, title_text="Seasonal Decomposition")
            # Format y-axis to show values in millions
            fig.update_yaxes(title_text="Sales (M)", tickformat=".1s", row=1, col=1)
            fig.update_yaxes(title_text="Trend (M)", tickformat=".1s", row=2, col=1)
            fig.update_yaxes(title_text="Seasonal (M)", tickformat=".1s", row=3, col=1)
            fig.update_yaxes(title_text="Residual (M)", tickformat=".1s", row=4, col=1)
            fig.show()
        except Exception as e:
            print(f"Could not perform seasonal decomposition: {str(e)}")

    # 6. Correlation Analysis
    print("\n\n6. CORRELATION ANALYSIS")
    print("="*40)

    # Full correlation matrix using Plotly
    print("Full Correlation Matrix:")
    corr = numeric_df.corr()
    # Corrected heatmap using go.Heatmap
    fig = go.Figure(data=go.Heatmap(
                        z=corr.values,
                        x=corr.columns,
                        y=corr.index,
                        colorscale='RdBu', # Changed colorscale to a valid one
                        zmid=0, # Center the color scale at 0
                        colorbar=dict(title="Correlation"),
                        text=corr.values.round(2), # Add text labels
                        texttemplate="%{text}" # Format text labels
                      ))

    fig.update_layout(title="Correlation Matrix - All Variables")
    fig.show()

    # Media variables correlation
    media_keywords = ['impressions', 'clicks', 'social', 'search', 'email', 'video']
    media_cols = [col for col in numeric_df.columns if any(keyword in col.lower() for keyword in media_keywords)]

    if media_cols and target_var in numeric_df.columns:
        print("Media Variables Correlation with Target:")
        media_corr = numeric_df[media_cols + [target_var]].corr()
        # Extract only correlations with target variable
        target_corr = media_corr[target_var].drop(target_var).sort_values(ascending=False)

        # Plot correlations as vertical bars using Plotly
        fig = px.bar(x=target_corr.index, y=target_corr.values * 100, title=f"Correlation of Media Variables with {target_var} (%)")
        fig.update_layout(
            xaxis_title="Media Variables",
            yaxis_title="Correlation Coefficient (%)",
            yaxis_ticksuffix="%", # Add percentage suffix
            xaxis_tickangle=-45
        )
        fig.show()


        # Also show as a table
        print((target_corr * 100).round(2).to_frame("Correlation (%)"))

        # 6.1 Media Execution Share Pie Chart
        print("\n\n6.1 MEDIA EXECUTION SHARE")
        print("="*40)

        # Calculate total media execution (sum of all media variables)
        media_totals = numeric_df[media_cols].sum()
        total_media = media_totals.sum()

        # Calculate share percentage
        media_share = (media_totals / total_media) * 100

        # Sort by share for better visualization
        media_share = media_share.sort_values(ascending=False)

        # Create pie chart
        fig = px.pie(values=media_share.values,
                     names=media_share.index,
                     title="Media Execution Share by Channel")
        fig.update_traces(textposition='inside', textinfo='percent+label')
        fig.show()

        # Display share percentages as table
        print("Media Execution Share Percentage:")
        display(media_share.round(2).to_frame("Share (%)"))

    # 7. Outlier Analysis
    print("\n\n7. OUTLIER ANALYSIS")
    print("="*40)

    # Check for outliers in target variable
    Q1 = data[target_var].quantile(0.25)
    Q3 = data[target_var].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR

    # Identify outliers
    outliers = data[(data[target_var] < lower_bound) | (data[target_var] > upper_bound)]
    normal_data = data[~((data[target_var] < lower_bound) | (data[target_var] > upper_bound))]
    print(f"Number of potential outliers in {target_var}: {len(outliers)}")

    if len(outliers) > 0:
        print("Outlier values:")
        display(outliers[['Week_Ending', target_var]])

        # Plot with outliers highlighted using Plotly
        fig = go.Figure()

        # Add normal values
        fig.add_trace(go.Scattergl(
            x=normal_data['Week_Ending'],
            y=normal_data[target_var],
            mode='markers',
            name='Normal Values',
            marker=dict(color='darkgreen', opacity=0.7, size=8)
        ))

        # Add outliers
        fig.add_trace(go.Scattergl(
            x=outliers['Week_Ending'],
            y=outliers[target_var],
            mode='markers',
            name='Outliers',
            marker=dict(color='red', opacity=0.9, size=10)
        ))

        # Add bounds lines
        fig.add_shape(type="line",
            x0=data['Week_Ending'].min(), y0=upper_bound, x1=data['Week_Ending'].max(), y1=upper_bound,
            line=dict(color="red", width=2, dash="dash"),
            name='Upper Bound'
        )
        fig.add_shape(type="line",
            x0=data['Week_Ending'].min(), y0=lower_bound, x1=data['Week_Ending'].max(), y1=lower_bound,
            line=dict(color="red", width=2, dash="dash"),
            name='Lower Bound'
        )


        fig.update_layout(
            title=f"Outlier Detection in {target_var}",
            xaxis_title="Date",
            yaxis_title=target_var,
            yaxis_tickformat=".1s" # Format y-axis to show values in millions
        )
        fig.show()


    # Return numeric_df and correlation matrix for interactive use
    return data, numeric_df, corr


# Main execution
if __name__ == "__main__":
    # Load and preprocess your data
    file_path = "/content/Book1.csv"  # Update this path to your file location
    data = load_and_preprocess_data(file_path)

    # Define the target variable here
    target_var = 'Sales'

    # Perform comprehensive EDA and get the data, numeric dataframe and correlation matrix
    data, numeric_df, correlations = perform_comprehensive_eda(data, target_var=target_var)

    # Save data to global scope
#     %store data
#     %store numeric_df
#     %store correlations

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
from statsmodels.tsa.seasonal import seasonal_decompose
from IPython.display import display

def feature_engineering_module(df):
    """
    Feature engineering module for time series data
    """
    print("\n===== FEATURE ENGG MODULE =====")

    # Check for required columns
    if 'Week_Ending' not in df.columns:
        raise ValueError("DataFrame must contain a 'Week_Ending' column")
    if 'Sales' not in df.columns:
        raise ValueError("DataFrame must contain a 'Sales' column")

    # Ensure we're working with a copy to avoid modifying original data
    df = df.copy()

    # Track original columns to identify new features later
    original_columns = set(df.columns)

    # Ensure datetime index
    df['Week_Ending'] = pd.to_datetime(df['Week_Ending'])
    df = df.set_index('Week_Ending').sort_index()

    # 1. Seasonal Index (SIndex) - With user-selectable period
    try:
        print("\nSelect seasonality period:")
        print("1. 4 weeks (monthly pattern)")
        print("2. 13 weeks (quarterly pattern)")
        print("3. 26 weeks (half-yearly pattern)")
        print("4. 52 weeks (yearly pattern)")
        print("5. Custom period")

        period_choice = input("Enter your choice (1-5): ").strip()

        if period_choice == "1":
            period = 4
        elif period_choice == "2":
            period = 13
        elif period_choice == "3":
            period = 26
        elif period_choice == "4":
            period = 52
        elif period_choice == "5":
            try:
                period = int(input("Enter custom period (number of weeks): ").strip())
            except:
                print("‚ö†Ô∏è Invalid input, using default period of 52 weeks")
                period = 52
        else:
            print("‚ö†Ô∏è Invalid choice, using default period of 52 weeks")
            period = 52

        if len(df) >= 2 * period:
            decomp = seasonal_decompose(df['Sales'], period=period, model='additive', extrapolate_trend='freq')
            df['SIndex'] = decomp.seasonal
            print(f"‚úÖ Seasonal Index created with period={period}")
        else:
            print(f"‚ö†Ô∏è Not enough data points ({len(df)}) for seasonality period {period}")
    except Exception as e:
        print(f"‚ö†Ô∏è Could not create Seasonal Index: {str(e)}")

    # 2. Holiday Dummies
    try:
        add_dummies = input("\nDo you want to add holiday dummies? (Y/N): ").strip().lower()
        if add_dummies == 'y':
            dates = input("Enter holiday dates (comma separated, format YYYY-MM-DD): ")
            if dates.strip():
                dates = [d.strip() for d in dates.split(",")]
                for i, d in enumerate(dates, start=1):
                    try:
                        holiday_date = pd.to_datetime(d)
                        col_name = f"Holiday_{i}"
                        df[col_name] = (df.index == holiday_date).astype(int)
                        print(f"‚úÖ Added dummy: {col_name} for {d}")
                    except:
                        print(f"‚ö†Ô∏è Could not parse date: {d}")
    except:
        print("‚ö†Ô∏è Skipping holiday dummies due to input issue")

    # 3. Split Variable
    try:
        split_choice = input("\nDo you want to split a variable at a date? (Y/N): ").strip().lower()
        if split_choice == 'y':
            print("\nAvailable variables:")
            all_vars = [col for col in df.columns if col not in ['SIndex']]
            for i, var in enumerate(all_vars, 1):
                print(f"{i}. {var}")

            try:
                var_idx = int(input("Select variable number to split: ")) - 1
                if 0 <= var_idx < len(all_vars):
                    var_name = all_vars[var_idx]
                    split_date = input("Enter split date (YYYY-MM-DD): ").strip()

                    try:
                        split_dt = pd.to_datetime(split_date)
                        df[f"{var_name}_pre"] = np.where(df.index <= split_dt, df[var_name], 0)
                        df[f"{var_name}_post"] = np.where(df.index > split_dt, df[var_name], 0)

                        # Drop the original variable as requested
                        df.drop(columns=[var_name], inplace=True)
                        print(f"‚úÖ Split {var_name} into {var_name}_pre and {var_name}_post at {split_dt.date()}")
                        print(f"‚úÖ Dropped original variable: {var_name}")
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error splitting variable: {str(e)}")
                else:
                    print("‚ö†Ô∏è Invalid selection")
            except:
                print("‚ö†Ô∏è Invalid input")
    except:
        print("‚ö†Ô∏è Skipping variable splitting due to input issue")

    # 4. Super Campaign - Enhanced with variable selection by number
    try:
        super_choice = input("\nDo you want to create a super campaign? (Y/N): ").strip().lower()
        if super_choice == 'y':
            print("\nAvailable variables:")
            all_vars = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
            for i, var in enumerate(all_vars, 1):
                print(f"{i}. {var}")

            try:
                selected = input("Enter variable numbers to combine (comma separated): ")
                var_indices = [int(x.strip())-1 for x in selected.split(",") if x.strip().isdigit()]
                vars_to_combine = [all_vars[i] for i in var_indices if 0 <= i < len(all_vars)]

                if vars_to_combine:
                    # Ask for custom name
                    name_choice = input("Do you want to provide a custom name? (Y/N): ").strip().lower()
                    if name_choice == 'y':
                        super_col = input("Enter the custom name: ").strip()
                    else:
                        super_col = "combined_var"

                    # Create the super campaign
                    df[super_col] = df[vars_to_combine].sum(axis=1)

                    # Display verification of sums
                    print(f"\nVerification of sums for {super_col}:")
                    for var in vars_to_combine:
                        print(f"{var}: {df[var].sum():.2f}")
                    print(f"{super_col}: {df[super_col].sum():.2f}")

                    # Drop the original variables as requested
                    df.drop(columns=vars_to_combine, inplace=True)
                    print(f"‚úÖ Created Super Campaign: {super_col} combining {vars_to_combine}")
                    print(f"‚úÖ Dropped original variables: {vars_to_combine}")
                else:
                    print("‚ö†Ô∏è No valid variables selected")
            except:
                print("‚ö†Ô∏è Invalid input")
    except:
        print("‚ö†Ô∏è Skipping super campaign creation due to input issue")

    # Show extra features created
    new_features = sorted(set(df.columns) - original_columns)

    if new_features:
        print("\nüìä EXTRA FEATURES CREATED:")
        print("=" * 50)

        # Create a summary table
        feature_info = []
        for col in new_features:
            if col == "SIndex":
                feature_type = "Seasonal Index"
            elif col.startswith("Holiday_"):
                feature_type = "Holiday Dummy"
            elif col.endswith(("_pre", "_post")):
                feature_type = "Split Variable"
            elif col == "combined_var" or col == "Super_Campaign":
                feature_type = "Super Campaign"
            else:
                feature_type = "Other"

            feature_info.append({
                "Feature Name": col,
                "Type": feature_type,
                "Data Type": str(df[col].dtype),
                "Non-Zero Values": f"{(df[col] != 0).sum()} / {len(df)}"
            })

        # Display as table
        display(pd.DataFrame(feature_info))

        # Show first few rows of new features
        print("\nüìã SAMPLE OF NEW FEATURES:")
        display(df[new_features].head())
    else:
        print("\n‚ÑπÔ∏è No additional features were created.")

    return df

def interactive_data_exploration(df_features):
    """
    Interactive data exploration function
    """
    print("\n\n===== INTERACTIVE DATA EXPLORATION =====")
    print("-" * 50)
    print("Ask questions about any variable in the dataset")
    print("Type 'N', 'NO', or 'no' to finish, 'variables' to see all available variables, or 'help' for examples")

    # Get all available variables for reference
    all_variables = list(df_features.columns)
    numeric_variables = list(df_features.select_dtypes(include=[np.number]).columns)

    # Recompute correlations with new features
    numeric_df_features = df_features.select_dtypes(include=[np.number])
    correlations = numeric_df_features.corr()

    # Simple question-answering mechanism
    while True:
        try:
            question = input("\nWhat would you like to know about your data? ").strip().lower()

            # Check for exit condition
            if question in ['n', 'no']:
                print("Exiting interactive mode...")
                break

        except:
            print("\nInput error. Exiting interactive mode.")
            break

        if question == 'variables':
            print("Available variables:")
            for var in all_variables:
                print(f"‚Ä¢ {var}")
            continue
        elif question == 'help':
            print("Examples of questions I can answer:")
            print("‚Ä¢ 'paid search' - Get comprehensive analysis of paid search metrics")
            print("‚Ä¢ 'discount1' - Analyze discount1 performance and relationship with sales")
            print("‚Ä¢ 'social media' - Explore all social media related metrics")
            print("‚Ä¢ 'trends' - View sales trends over time")
            print("‚Ä¢ 'correlations' - See strongest correlations with sales")
            print("‚Ä¢ 'seasonality' - Analyze seasonal patterns in sales")
            print("‚Ä¢ 'holidays' - Analyze holiday impacts on sales")
            print("‚Ä¢ 'split variables' - Show information about split variables")
            print("‚Ä¢ 'super campaign' - Show information about super campaign")
            print("‚Ä¢ 'sales correlation with paid search' - Get correlation between sales and paid search")
            continue

        # Check for special queries about feature engineering elements
        if 'seasonal' in question or 'sindex' in question:
            if 'SIndex' in df_features.columns:
                print("\nSEASONALITY ANALYSIS:")
                print("=" * 50)

                # Calculate seasonal strength
                seasonal_strength = df_features['SIndex'].std() / df_features['Sales'].std() * 100
                print(f"Seasonal strength: {seasonal_strength:.1f}% of sales variation")

                # Find strongest seasonal periods
                seasonal_peaks = df_features['SIndex'].nlargest(5)
                seasonal_troughs = df_features['SIndex'].nsmallest(5)

                print("\nStrongest seasonal peaks:")
                for date, value in seasonal_peaks.items():
                    print(f"‚Ä¢ {date.strftime('%Y-%m-%d')}: {value:,.0f}")

                print("\nStrongest seasonal troughs:")
                for date, value in seasonal_troughs.items():
                    print(f"‚Ä¢ {date.strftime('%Y-%m-%d')}: {value:,.0f}")
            else:
                print("No seasonal index found. Run feature engineering to create SIndex.")
            continue

        if 'holiday' in question:
            holiday_cols = [col for col in df_features.columns if col.startswith('Holiday_')]
            if holiday_cols:
                print("\nHOLIDAY ANALYSIS:")
                print("=" * 50)

                for col in holiday_cols:
                    holiday_dates = df_features[df_features[col] == 1].index
                    if not holiday_dates.empty:
                        print(f"\n{col}:")
                        for date in holiday_dates:
                            # Get sales on holiday vs average
                            holiday_sales = df_features.loc[date, 'Sales']
                            avg_sales = df_features['Sales'].mean()
                            pct_diff = (holiday_sales - avg_sales) / avg_sales * 100
                            print(f"‚Ä¢ {date.strftime('%Y-%m-%d')}: Sales ‚Çπ{holiday_sales:,.0f} ({pct_diff:+.1f}% vs average)")
            else:
                print("No holiday dummies found. You can add them in the feature engineering module.")
            continue

        if 'split' in question:
            split_cols = [col for col in df_features.columns if col.endswith(('_pre', '_post'))]
            if split_cols:
                print("\nSPLIT VARIABLES ANALYSIS:")
                print("=" * 50)

                # Group by root variable
                split_roots = {}
                for col in split_cols:
                    root = col.rsplit('_', 1)[0]
                    if root not in split_roots:
                        split_roots[root] = []
                    split_roots[root].append(col)

                for root, cols in split_roots.items():
                    print(f"\n{root}:")
                    for col in cols:
                        period = "before" if col.endswith('_pre') else "after"
                        avg_val = df_features[col].mean()
                        print(f"‚Ä¢ {col}: Average value {period} split: {avg_val:,.2f}")
            else:
                print("No split variables found. You can create them in the feature engineering module.")
            continue

        if 'super campaign' in question or 'combined' in question:
            super_cols = [col for col in df_features.columns if col in ['Super_Campaign', 'combined_var'] or 'super' in col.lower()]
            if super_cols:
                for super_col in super_cols:
                    print("\nSUPER CAMPAIGN ANALYSIS:")
                    print("=" * 50)

                    # Calculate correlation with sales
                    if 'Sales' in df_features.columns:
                        corr = df_features[super_col].corr(df_features['Sales'])
                        print(f"Correlation with sales: {corr:.3f}")

                    # Summary stats
                    avg_campaign = df_features[super_col].mean()
                    max_campaign = df_features[super_col].max()
                    min_campaign = df_features[super_col].min()

                    print(f"Average {super_col} value: {avg_campaign:,.2f}")
                    print(f"Maximum {super_col} value: {max_campaign:,.2f}")
                    print(f"Minimum {super_col} value: {min_campaign:,.2f}")

                    # Show contribution of original variables if available
                    print(f"Total {super_col} spend: {df_features[super_col].sum():,.2f}")
            else:
                print("No super campaign found. You can create one in the feature engineering module.")
            continue

        # Check for correlation questions
        if 'correlation' in question or 'relationship' in question:
            # Extract variable names from question
            mentioned_vars = [var for var in all_variables if var.lower() in question]

            if 'sales' in question and len(mentioned_vars) > 1:
                # Show correlation between sales and mentioned variables
                for var in mentioned_vars:
                    if var != 'Sales' and var in numeric_variables:
                        corr = df_features['Sales'].corr(df_features[var])
                        direction = "positive" if corr > 0 else "negative"
                        strength = "strong" if abs(corr) > 0.7 else "moderate" if abs(corr) > 0.3 else "weak"
                        print(f"Correlation between Sales and {var}: {corr:.3f} ({strength} {direction} relationship)")
            else:
                # Show top correlations with sales
                if 'Sales' in correlations.index:
                    strong_corrs = correlations['Sales'].drop('Sales').abs().sort_values(ascending=False)
                    # Filter for strong correlations (e.g., abs value > 0.4) and get original correlation values
                    strong_corrs = correlations['Sales'].loc[strong_corrs[strong_corrs > 0.4].index]

                    if not strong_corrs.empty:
                        print("Strongest relationships with sales:")
                        for var, corr in strong_corrs.items():
                            direction = "positive" if corr > 0 else "negative"
                            print(f"‚Ä¢ {var}: {corr:.3f} ({direction})")
                    else:
                        print("No strong correlations found (|r| > 0.4) with Sales.")
                else:
                    print("Target variable 'Sales' not found in correlation matrix.")
            continue

        # Check for other special queries
        if 'trend' in question:
            # Show sales trends
            trend_data = df_features[['Sales']].copy()
            overall_trend = "increasing" if trend_data['Sales'].iloc[-1] > trend_data['Sales'].iloc[0] else "decreasing"

            # Handle potential division by zero if the first value is 0
            if trend_data['Sales'].iloc[0] != 0:
                change_pct = (trend_data['Sales'].iloc[-1] - trend_data['Sales'].iloc[0]) / trend_data['Sales'].iloc[0] * 100
                print(f"Sales show an {overall_trend} trend overall ({change_pct:+.1f}% change)")
            else:
                print(f"Sales show an {overall_trend} trend overall (starting from zero)")

            # Show monthly trends if available
            if len(trend_data) >= 12:
                monthly_avg = trend_data.resample('M').mean()
                if not monthly_avg.empty:
                    best_month = monthly_avg.idxmax()[0].strftime('%B')
                    worst_month = monthly_avg.idxmin()[0].strftime('%B')
                    print(f"Best month: {best_month}, Worst month: {worst_month}")
                else:
                    print("Not enough data for monthly trend analysis.")
            continue

        # Find matching variables
        matching_vars = [var for var in all_variables if question in var.lower()]

        if not matching_vars:
            # Try to understand what the user might be asking about
            if any(word in question for word in ['sale', 'revenue', 'income']):
                print(f"Analysis for Sales:")
                print(f"Range: ‚Çπ{df_features['Sales'].min():,.0f} to ‚Çπ{df_features['Sales'].max():,.0f}")
                print(f"Average: ‚Çπ{df_features['Sales'].mean():,.0f}")
                print(f"Standard Deviation: ‚Çπ{df_features['Sales'].std():,.0f}")

                # Calculate growth rate
                first_value = df_features['Sales'].iloc[0]
                last_value = df_features['Sales'].iloc[-1]
                # Handle potential division by zero if the first value is 0
                if first_value != 0:
                    growth_pct = (last_value - first_value) / first_value * 100
                    print(f"Growth over period: {growth_pct:+.1f}%")
                else:
                    print(f"Growth over period: Infinite (starting from zero)")
            else:
                # Try fuzzy matching for similar variable names
                import difflib
                suggestions = difflib.get_close_matches(question, all_variables, n=3, cutoff=0.3)
                if suggestions:
                    print(f"Variable '{question}' not found. Did you mean: {', '.join(suggestions)}?")
                else:
                    print(f"Variable '{question}' not found. Type 'variables' to see all available variables.")
            continue

        # Process each matching variable
        for var in matching_vars:
            print(f"\n{'='*50}")
            print(f"COMPREHENSIVE ANALYSIS FOR: {var}")
            print(f"{'='*50}")

            # Basic variable information
            if var in numeric_variables:
                print(f"Type: Numeric")
                print(f"Range: {df_features[var].min():,.2f} to {df_features[var].max():,.2f}")
                print(f"Mean: {df_features[var].mean():,.2f}")
                print(f"Standard Deviation: {df_features[var].std():,.2f}")
                print(f"Missing Values: {df_features[var].isnull().sum()} ({df_features[var].isnull().sum()/len(df_features)*100:.1f}%)")

                # Distribution shape
                skewness = df_features[var].skew()
                if abs(skewness) > 1:
                    shape = "highly skewed"
                elif abs(skewness) > 0.5:
                    shape = "moderately skewed"
                else:
                    shape = "approximately symmetric"
                print(f"Distribution: {shape} (skewness: {skewness:.2f})")
            else:
                print(f"Type: Categorical")
                print(f"Unique values: {df_features[var].nunique()}")
                if df_features[var].nunique() <= 10:
                    print("Value counts:")
                    print(df_features[var].value_counts())

            # Relationship with target variable
            if var in numeric_variables and var != 'Sales' and 'Sales' in df_features.columns:
                corr = df_features[var].corr(df_features['Sales'])
                print(f"\nRELATIONSHIP WITH Sales:")
                print(f"Correlation coefficient: {corr:.3f}")

                if abs(corr) > 0.7:
                    strength = "very strong"
                elif abs(corr) > 0.5:
                    strength = "strong"
                elif abs(corr) > 0.3:
                    strength = "moderate"
                elif abs(corr) > 0.1:
                    strength = "weak"
                else:
                    strength = "very weak or no"

                direction = "positive" if corr > 0 else "negative"
                print(f"‚Üí {strength} {direction} relationship with sales")

                # Estimate impact
                if df_features[var].std() > 0:
                    # Calculate the estimated change in Sales for a one standard deviation change in the current variable
                    estimated_sales_change_per_std = corr * df_features['Sales'].std()
                    print(f"‚Üí A one standard deviation increase in {var} is associated with an estimated ‚Çπ{estimated_sales_change_per_std:,.0f} change in sales.")

            # Time trend analysis
            # Calculate trend
            trend_data = df_features[[var]].copy()
            if len(trend_data) > 1:
                overall_trend = "increasing" if trend_data[var].iloc[-1] > trend_data[var].iloc[0] else "decreasing"
                # Handle potential division by zero if the first value is 0
                change_pct = (trend_data[var].iloc[-1] - trend_data[var].iloc[0]) / trend_data[var].iloc[0] * 100 if trend_data[var].iloc[0] != 0 else float('inf') if trend_data[var].iloc[-1] > 0 else 0

                print(f"\nTIME TREND ANALYSIS:")
                if change_pct == float('inf'):
                    print(f"‚Üí Overall {overall_trend} trend (infinite percentage change from zero start)")
                else:
                    print(f"‚Üí Overall {overall_trend} trend ({change_pct:+.1f}% change)")

                # Check for seasonality
                if len(trend_data) >= 12:
                    monthly_avg = trend_data.resample('M').mean()
                    if len(monthly_avg) > 3 and monthly_avg[var].mean() != 0:
                        seasonal_variation = (monthly_avg[var].max() - monthly_avg[var].min()) / monthly_avg[var].mean() * 100
                        print(f"‚Üí Seasonal variation: {seasonal_variation:.1f}%")
                    elif monthly_avg[var].mean() == 0:
                        print(f"‚Üí Seasonal variation: Infinite (average is zero)")
                    else:
                        print("‚Üí Not enough data points for meaningful seasonal variation analysis.")

            # Compare with other variables in the same category
            if any(kw in var.lower() for kw in ['discount', 'promo']):
                discount_vars = [v for v in numeric_variables if any(kw in v.lower() for kw in ['discount', 'promo'])]
                if len(discount_vars) > 1:
                    print(f"\nCOMPARISON WITH OTHER DISCOUNT VARIABLES:")
                    for d_var in discount_vars:
                        if d_var != var:
                            d_corr = df_features[d_var].corr(df_features['Sales'])
                            print(f"‚Üí {d_var}: r = {d_corr:.3f}")

            if any(kw in var.lower() for kw in ['search', 'impression', 'click', 'social', 'email', 'video']):
                media_vars = [v for v in numeric_variables if any(kw in v.lower() for kw in ['search', 'impression', 'click', 'social', 'email', 'video'])]
                if len(media_vars) > 1:
                    print(f"\nCOMPARISON WITH OTHER MEDIA VARIABLES:")
                    for m_var in media_vars:
                        if m_var != var:
                            m_corr = df_features[m_var].corr(df_features['Sales'])
                            print(f"‚Üí {m_var}: r = {m_corr:.3f}")

            print(f"\nRECOMMENDATION FOR {var}:")
            if var in numeric_variables and var != 'Sales' and 'Sales' in df_features.columns:
                corr = df_features[var].corr(df_features['Sales'])
                if corr > 0.4:
                    print("‚Üí Consider increasing investment in this area as it strongly correlates with sales")
                elif corr > 0.2:
                    print("‚Üí This area shows positive correlation with sales, consider testing increased investment")
                elif corr < -0.2:
                    print("‚Üí This area shows negative correlation with sales, consider investigating further")
                else:
                    print("‚Üí No strong relationship with sales detected")

    # Show finalized list of variables by bucket after interactive session
    print("\n\n===== FINALIZED VARIABLES BY BUCKET =====")
    print("-" * 50)

    # Categorize variables
    base_vars = [col for col in df_features.columns if not col.startswith(('Holiday_', 'SIndex')) and not col.endswith(('_pre', '_post')) and col != 'Sales' and col not in ['combined_var', 'Super_Campaign']]
    holiday_vars = [col for col in df_features.columns if col.startswith('Holiday_')]
    split_vars = [col for col in df_features.columns if col.endswith(('_pre', '_post'))]
    seasonal_vars = [col for col in df_features.columns if col == 'SIndex']
    super_vars = [col for col in df_features.columns if col in ['combined_var', 'Super_Campaign']]

    print("TARGET VARIABLE:")
    print(f"‚Ä¢ Sales")

    print("\nINDEPENDENT VARIABLES:")
    print("\nBase Variables:")
    for var in base_vars:
        print(f"‚Ä¢ {var}")

    print("\nHoliday Dummies:")
    for var in holiday_vars:
        print(f"‚Ä¢ {var}")

    print("\nSplit Variables:")
    for var in split_vars:
        print(f"‚Ä¢ {var}")

    print("\nSeasonal Index:")
    for var in seasonal_vars:
        print(f"‚Ä¢ {var}")

    print("\nSuper Campaign:")
    for var in super_vars:
        print(f"‚Ä¢ {var}")

# Check if data is available before running feature engineering
try:
    data
except NameError:
    print("‚ùå ERROR: 'data' is not defined. Please run your data loading code first.")
    raise # Re-raise the error to stop execution

# Run feature engineering
df_features = feature_engineering_module(data)

# Save df_features to global scope
# %store df_features

# Run interactive data exploration
interactive_data_exploration(df_features)

# ================================================
# UPDATED VARIABLE BUCKETING
# ================================================
def variable_bucketing(df):
    """
    Categorizes variables into different buckets for modeling
    with SIndex and Holidays moved to Base Variables
    """
    print("\n===== VARIABLE BUCKETING =====")

    # Get all column names
    all_columns = df.columns.tolist()

    # Define buckets
    buckets = {
        'Media Variables': [],
        'Base Variables': [],
        'Promo Variables': [],
        'Extra Features': [],  # This will now only contain split variables
        'Other Variables': []
    }

    # Media variables (keywords to identify media variables)
    media_keywords = ['impression', 'click', 'social', 'search', 'email', 'video', 'media', 'campaign', 'ad', 'spend']
    for col in all_columns:
        if any(keyword in col.lower() for keyword in media_keywords):
            buckets['Media Variables'].append(col)

    # Promo variables (discount-related)
    promo_keywords = ['discount', 'promo', 'promotion', 'offer']
    for col in all_columns:
        if any(keyword in col.lower() for keyword in promo_keywords):
            buckets['Promo Variables'].append(col)

    # Extra features (only split variables now)
    split_keywords = ['_pre', '_post']
    for col in all_columns:
        if any(keyword in col.lower() for keyword in split_keywords):
            buckets['Extra Features'].append(col)

    # Base variables (everything else excluding Sales and date index)
    # This now includes SIndex and Holidays
    base_exclusions = ['sales', 'week_ending'] + buckets['Media Variables'] + buckets['Promo Variables'] + buckets['Extra Features']
    for col in all_columns:
        if col.lower() not in [excl.lower() for excl in base_exclusions]:
            buckets['Base Variables'].append(col)

    # Remove duplicates (if any variable was categorized in multiple buckets)
    for bucket_name in buckets:
        buckets[bucket_name] = list(set(buckets[bucket_name]))

    # Display the bucketing results
    print("üìä VARIABLE BUCKETS:")
    print("=" * 50)

    for bucket_name, variables in buckets.items():
        print(f"\n{bucket_name.upper()} ({len(variables)} variables):")
        if variables:
            for var in sorted(variables):
                print(f"  - {var}")
        else:
            print("  (None)")

    return buckets

# Apply the updated variable bucketing
variable_buckets = variable_bucketing(df_features)

# ================================================
# MODEL PREPROCESSING MODULE
# ================================================
from sklearn.preprocessing import StandardScaler

def model_preprocessing(df, feature_columns, target_column='Sales', test_size=0.2):
    """
    Preprocess data for modeling: scaling and time-based train-test split

    Parameters:
    df (DataFrame): Input dataframe with all variables
    feature_columns (list): List of independent variables
    target_column (str): Name of the target variable (default: 'Sales')
    test_size (float): Proportion of data to use for testing (default: 0.2)

    Returns:
    tuple: X_train_scaled, X_test_scaled, y_train, y_test, scaler
    """
    print("\n===== MODEL PREPROCESSING =====")

    # Separate features and target
    X = df[feature_columns].copy()
    y = df[target_column].copy()

    print(f"Original feature shapes: X={X.shape}, y={y.shape}")

    # Time-based train-test split (not random for time series)
    split_idx = int(len(X) * (1 - test_size))

    X_train = X.iloc[:split_idx].copy()
    X_test = X.iloc[split_idx:].copy()
    y_train = y.iloc[:split_idx].copy()
    y_test = y.iloc[split_idx:].copy()

    print(f"After time-based split:")
    print(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
    print(f"y_train: {y_train.shape}, y_test: {y_test.shape}")

    # Scale the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Convert back to DataFrames with original column names and indices
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)

    print("‚úÖ Features scaled using StandardScaler")
    print("‚úÖ Time-based train-test split completed")

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# Ensure df_features is defined (assuming it's created in a previous step)
if 'df_features' not in globals():
    print("‚ùå ERROR: 'df_features' is not defined. Please run the feature engineering code first.")
    raise NameError("'df_features' is not defined")

# Make sure final_variables is defined
if 'final_variables' not in globals():
    print("‚ö†Ô∏è  final_variables not found. Creating from df_features columns...")
    # Create final_variables by excluding non-feature columns
    exclude_cols = ['Week_Ending', 'Sales']  # Add any other columns to exclude
    final_variables = [col for col in df_features.columns if col not in exclude_cols]
    # Explicitly remove any 'None' values if they somehow got added
    final_variables = [col for col in final_variables if col is not None and col != 'None']
    print(f"Created final_variables: {final_variables}")
else:
    # If final_variables is already defined, ensure no 'None' values are present
    final_variables = [col for col in final_variables if col is not None and col != 'None']
    print(f"Using existing final_variables: {final_variables}")


# Apply preprocessing to your data
X_train_scaled, X_test_scaled, y_train, y_test, scaler = model_preprocessing(
    df_features,
    final_variables,
    target_column='Sales',
    test_size=0.2
)

# Display preview of scaled training data
print("\nüìä PREVIEW OF SCALED TRAINING DATA (first 5 rows):")
display(X_train_scaled.head())

print("\nüìä PREVIEW OF TARGET VARIABLE (first 5 rows):")
display(y_train.head())

# ================================================
# COMPLETE MARKETING MIX MODELING PIPELINE
# ================================================
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from statsmodels.stats.outliers_influence import variance_inflation_factor
from IPython.display import display

# First, let's make sure we have the data
try:
    # Check if data is available
    data
except NameError:
    print("‚ùå ERROR: 'data' is not defined. Please run your data loading code first.")
    # You need to run your data loading code here
    # For example: data = load_and_preprocess_data(file_path)
    raise

# If you've already run feature engineering, use df_features
# Otherwise, we need to run feature engineering first
if 'df_features' not in globals():
    print("‚ö†Ô∏è  df_features not found. Running feature engineering...")

    # Run your feature engineering code here
    # This should be the feature_engineering_module function you created earlier
    df_features = feature_engineering_module(data)
else:
    print("‚úÖ df_features found. Proceeding with modeling preparation.")

# Make sure final_variables is defined
if 'final_variables' not in globals():
    print("‚ö†Ô∏è  final_variables not found. Creating from df_features columns...")
    # Create final_variables by excluding non-feature columns
    exclude_cols = ['Week_Ending', 'Sales']  # Add any other columns to exclude
    final_variables = [col for col in df_features.columns if col not in exclude_cols]
    print(f"Created final_variables: {final_variables}")

# Now run the complete model preparation
def complete_model_preparation(df, feature_columns, target_column='Sales', test_size=0.2):
    """
    Complete model preparation with preprocessing and multicollinearity analysis
    """
    print("\n===== COMPLETE MODEL PREPARATION =====")

    # 1. Preprocessing
    print("\n1. DATA PREPROCESSING")
    print("=" * 30)

    # Separate features and target
    X = df[feature_columns].copy()
    y = df[target_column].copy()

    # Time-based train-test split
    split_idx = int(len(X) * (1 - test_size))
    X_train = X.iloc[:split_idx]
    X_test = X.iloc[split_idx:]
    y_train = y.iloc[:split_idx]
    y_test = y.iloc[split_idx:]

    # Scale the features
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    # Convert back to DataFrames
    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)

    print("‚úÖ Preprocessing completed")
    print(f"Training set: {X_train_scaled.shape}")
    print(f"Testing set: {X_test_scaled.shape}")

    # 2. Multicollinearity Analysis
    print("\n2. MULTICOLLINEARITY ANALYSIS")
    print("=" * 30)

    # Calculate VIF for each feature
    vif_data = pd.DataFrame()
    vif_data["Feature"] = X_train_scaled.columns
    vif_data["VIF"] = [variance_inflation_factor(X_train_scaled.values, i)
                       for i in range(len(X_train_scaled.columns))]
    vif_data = vif_data.sort_values("VIF", ascending=False)

    # Display VIF results
    print("VIF Results:")
    display(vif_data)

    # 3. Analyze multicollinearity pattern
    print("\n3. MULTICOLLINEARITY PATTERN ANALYSIS")
    print("=" * 30)

    high_vif_features = vif_data[vif_data["VIF"] > 10]["Feature"].tolist()
    if high_vif_features:
        print(f"High VIF features: {high_vif_features}")
        corr_matrix = X_train_scaled[high_vif_features].corr()
        print("Correlation between high VIF variables:")
        display(corr_matrix)

    # 4. Business context evaluation
    print("\n4. BUSINESS CONTEXT EVALUATION")
    print("=" * 30)
    print("""
The high VIF between split variables is EXPECTED because they are derived from
the same original variable. This is a modeling choice rather than a statistical problem.

Recommended approach for marketing mix modeling:
1. Keep the split variables to capture different effects over time
2. Use regularized regression (ElasticNet) to handle multicollinearity
3. Validate model stability with cross-validation
""")

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler, vif_data

# Run the complete preparation process
X_train_scaled, X_test_scaled, y_train, y_test, scaler, vif_results = complete_model_preparation(
    df_features,
    final_variables,
    target_column='Sales',
    test_size=0.2
)

print("\n‚úÖ MODEL PREPARATION COMPLETE")
print("You can now proceed with regularized model building (ElasticNet recommended)")

# ================================================
# MODEL SELECTION (INTERACTIVE) ‚Äî NO TRAINING HERE
# ================================================
# What this cell does:
# 1) Lets the user choose a model from a dropdown: Ridge, Lasso, ElasticNet
# 2) Asks "why?" via a multi-select checklist + a free-text box
# 3) On confirm, saves a config dict -> MODEL_CHOICE (with default param grids)
# 4) Prints what will be used later. DOES NOT TRAIN.

from datetime import datetime

# Default hyperparameter grids you can tweak later (NOT used here)
_DEFAULT_GRIDS = {
    "ridge":      {"alpha": [0.01, 0.1, 1.0, 10.0, 100.0]},
    "lasso":      {"alpha": [0.0001, 0.001, 0.01, 0.1, 1.0], "max_iter": [10000]},
    "elasticnet": {"alpha": [0.0001, 0.001, 0.01, 0.1, 1.0], "l1_ratio": [0.2, 0.5, 0.8], "max_iter": [10000]},
}

# Short guidance text used in the UI
_GUIDE = {
    "ridge": (
        "Ridge (L2): good when many predictors are correlated and you want to keep them; "
        "shrinks coefficients but rarely to zero."
    ),
    "lasso": (
        "Lasso (L1): useful for feature selection (drives some coefficients to zero); "
        "can be unstable with strong multicollinearity."
    ),
    "elasticnet": (
        "ElasticNet (L1+L2): balances feature selection and stability; "
        "often a safe default for correlated media channels."
    ),
}

# Will be populated after confirmation
MODEL_CHOICE = None   # dict with keys: model, reasons, notes, grid, timestamp

# Try to use ipywidgets UI; if unavailable, fall back to CLI prompts.
try:
    import ipywidgets as widgets
    from IPython.display import display, clear_output

    # --- Widgets ---
    model_dd = widgets.Dropdown(
        options=[("ElasticNet", "elasticnet"), ("Ridge", "ridge"), ("Lasso", "lasso")],
        value="elasticnet",
        description="Model:",
        disabled=False,
    )

    reasons_ms = widgets.SelectMultiple(
        options=[
            "High multicollinearity",
            "Need feature selection",
            "Balance selection & stability",
            "Small dataset",
            "Interpretability matters",
            "Sparse true drivers expected",
            "Reduce overfitting risk",
        ],
        value=("Balance selection & stability",),
        description="Why?",
        rows=6,
        disabled=False,
        layout=widgets.Layout(width="50%"),
    )

    notes_txt = widgets.Textarea(
        placeholder="Write your hypothesis/business reasoning (e.g., 'channels are correlated; want stability + some selection').",
        description="Notes:",
        layout=widgets.Layout(width="90%", height="80px"),
    )

    explain_btn = widgets.Button(description="Explain choice", icon="info")
    confirm_btn = widgets.Button(description="Confirm selection", button_style="success", icon="check")
    out = widgets.Output()

    def _explain_choice(_btn=None):
        with out:
            clear_output(wait=True)
            m = model_dd.value
            print(f"Model selected: {m.title()}")
            print("-" * 60)
            print(_GUIDE[m])
            print("\nDefault grid (editable later):", _DEFAULT_GRIDS[m])

    def _confirm_choice(_btn=None):
        global MODEL_CHOICE
        m = model_dd.value
        MODEL_CHOICE = {
            "model": m,
            "reasons": list(reasons_ms.value),
            "notes": (notes_txt.value or "").strip(),
            "grid": _DEFAULT_GRIDS[m].copy(),
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "ready_to_train": False,   # enforce no training yet
        }
        with out:
            clear_output(wait=True)
            print("‚úÖ Selection stored in MODEL_CHOICE (no model has been fit).")
            print("Summary:")
            print(f"  ‚Ä¢ Model: {MODEL_CHOICE['model'].title()}")
            print(f"  ‚Ä¢ Reasons: {MODEL_CHOICE['reasons'] or '(none)'}")
            print(f"  ‚Ä¢ Notes: {MODEL_CHOICE['notes'] or '(none)'}")
            print(f"  ‚Ä¢ Param grid: {MODEL_CHOICE['grid']}")
            print("\nNext step suggestion (when you‚Äôre ready):")
            print("  ‚Üí Review/adjust the grid above, then pass MODEL_CHOICE to your training cell.")

    explain_btn.on_click(_explain_choice)
    confirm_btn.on_click(_confirm_choice)

    header = widgets.HTML("<h3>Model Selection ‚Äî confirm before any training</h3>")
    ui = widgets.VBox([
        header,
        model_dd,
        reasons_ms,
        notes_txt,
        widgets.HBox([explain_btn, confirm_btn]),
        out
    ])
    display(ui)
    _explain_choice()  # show guidance initially

except Exception as _e:
    # ---- CLI Fallback (no widgets) ----
    print("Widgets not available; using simple prompts (no training will run).")
    print("Choose model: [1] ElasticNet  [2] Ridge  [3] Lasso")
    choice = input("Enter 1/2/3: ").strip()
    mapping = {"1": "elasticnet", "2": "ridge", "3": "lasso"}
    m = mapping.get(choice, "elasticnet")
    print("\nSelect reasons (comma-separated numbers):")
    opts = [
        "High multicollinearity",
        "Need feature selection",
        "Balance selection & stability",
        "Small dataset",
        "Interpretability matters",
        "Sparse true drivers expected",
        "Reduce overfitting risk",
    ]
    for i, o in enumerate(opts, 1):
        print(f"{i}. {o}")
    sel = input("Your choices: ").strip()
    picked = []
    if sel:
        for s in sel.split(","):
            s = s.strip()
            if s.isdigit() and 1 <= int(s) <= len(opts):
                picked.append(opts[int(s) - 1])
    notes = input("Notes / hypothesis (optional): ").strip()

    MODEL_CHOICE = {
        "model": m,
        "reasons": picked,
        "notes": notes,
        "grid": _DEFAULT_GRIDS[m].copy(),
        "timestamp": datetime.utcnow().isoformat() + "Z",
        "ready_to_train": False,
    }

    print("\n‚úÖ Selection stored in MODEL_CHOICE (no model has been fit).")
    print("Summary:")
    print(f"  ‚Ä¢ Model: {MODEL_CHOICE['model'].title()}")
    print(f"  ‚Ä¢ Reasons: {MODEL_CHOICE['reasons'] or '(none)'}")
    print(f"  ‚Ä¢ Notes: {MODEL_CHOICE['notes'] or '(none)'}")
    print(f"  ‚Ä¢ Param grid: {MODEL_CHOICE['grid']}")
    print("\nWhen ready, hand MODEL_CHOICE to your training cell.")

# ----------------- LAST CELL: Full interactive MMM results (Plotly, uses existing df & MODEL_CHOICE) -----------------
import math, numpy as np, pandas as pd
import plotly.express as px, plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import r2_score, mean_squared_error
from statsmodels.stats.stattools import durbin_watson

# -------- CONFIG (quick edits allowed) --------
TARGET = "Sales"
WEEK_COL = "Week_Ending"
PROMO_KEYS = ["Discount1", "Discount2"]
HOLDOUT_WEEKS = 8
ADSTOCK_DEFAULT_THETA = 0.4
SAT_DEFAULT_BETA = 1e-6
MEP_PCT = 0.05
OPT_PCT = 0.80
DIM_THRESH_PCT = 0.01
# ---------------------------------------------

# ---- Validate prerequisites ----
if 'df_features' not in globals():
    raise RuntimeError("DataFrame `df_features` not found in notebook. Load and preprocess earlier cells first.")
if 'MODEL_CHOICE' not in globals() or not MODEL_CHOICE or 'model' not in MODEL_CHOICE:
    raise RuntimeError("MODEL_CHOICE not found. Run model selection cell first and confirm MODEL_CHOICE.")

cols = df_features.columns.tolist()
col_map_lower = {c.lower(): c for c in cols}

# Identify promo vars
promo_vars = [col_map_lower[c.lower()] for c in PROMO_KEYS if c.lower() in col_map_lower]

# Identify paid media
paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
paid_media = [c for c in cols if any(k in c.lower() for k in paid_keywords)
              and 'organic' not in c.lower()
              and c not in promo_vars
              and c!=TARGET and c!=WEEK_COL]

media_all = [c for c in cols if c not in promo_vars + [TARGET, WEEK_COL]]
base_vars = [c for c in cols if c not in promo_vars + media_all + [TARGET, WEEK_COL]]
for c in cols:
    if c not in promo_vars + media_all + base_vars + [TARGET, WEEK_COL]:
        base_vars.append(c)

# Ensure uniqueness
promo_vars = list(dict.fromkeys(promo_vars))
paid_media = list(dict.fromkeys(paid_media))
media_all = list(dict.fromkeys(media_all))
base_vars = list(dict.fromkeys(base_vars))

print(f"Detected paid media: {paid_media}")
print(f"Detected media (all): {media_all[:10]} (showing up to 10)")
print(f"Promo vars: {promo_vars}")
print(f"Base vars: {base_vars[:10]}")

# ---- User input for adstock/saturation ----
use_manual = None
try:
    ans = input("Do you want to provide adstock (theta) and saturation (beta) for paid media? (y/n) : ").strip().lower()
    use_manual = (ans in ['y','yes'])
except Exception:
    use_manual = False

manual_theta, manual_beta = {}, {}
if use_manual and len(paid_media)>0:
    print("Enter parameters for each paid media. Press Enter to skip.")
    for m in paid_media:
        raw_theta = input(f" - {m} theta (0..1): ").strip()
        raw_beta = input(f" - {m} beta: ").strip()
        if raw_theta:
            try: manual_theta[m] = float(raw_theta)
            except: pass
        if raw_beta:
            try: manual_beta[m] = float(raw_beta)
            except: pass
else:
    print("Proceeding with auto-estimation for adstock/saturation.")

# ---- Helpers ----
def adstock_geometric(x, theta):
    out = np.zeros_like(x, dtype=float)
    for t in range(len(x)):
        out[t] = x[t] + (theta*out[t-1] if t>0 else x[t])
    return out

def sat_1mexp(x, beta):
    return 1.0 - np.exp(-beta * np.clip(x,0,None))

def auto_theta(series):
    s = pd.Series(series).fillna(0.0)
    if len(s)<3 or s.std()==0: return ADSTOCK_DEFAULT_THETA
    ac1 = s.autocorr(lag=1)
    return float(np.clip(ac1 if not pd.isna(ac1) else ADSTOCK_DEFAULT_THETA, 0.0,0.9))

def auto_beta(x_ad):
    med = np.median(x_ad[x_ad>0]) if np.any(x_ad>0) else 0.0
    return float(np.log(2.0)/(med+1e-12)) if med>0 else SAT_DEFAULT_BETA

# ---- Transform features ----
X_trans, param_store = pd.DataFrame(index=df_features.index), {}
for c in media_all + promo_vars:
    raw = df_features[c].fillna(0.0).astype(float).values
    if c in paid_media:
        theta = manual_theta.get(c, auto_theta(raw))
        beta = manual_beta.get(c, None)
        x_ad = adstock_geometric(raw, theta)
        if beta is None: beta = auto_beta(x_ad)
        x_sat = sat_1mexp(x_ad, beta)
        scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
        x_final = x_sat*scale
        param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
    else:
        x_final = raw
        param_store[c] = {"theta":None,"beta":None,"scale":1.0}
    X_trans[c] = x_final

for b in base_vars:
    if b not in X_trans and b in df_features:
        X_trans[b] = df_features[b].fillna(0).astype(float)
for p in promo_vars:
    if p not in X_trans and p in df_features:
        X_trans[p] = df_features[p].fillna(0).astype(float)

feature_cols = [c for c in X_trans.columns if c!=TARGET]
X_full, y = X_trans[feature_cols], df_features[TARGET].astype(float).values

# ---- Train/test ----
n, hold = len(df_features), min(HOLDOUT_WEEKS,max(1,HOLDOUT_WEEKS))
train_n = n - hold
X_train, X_test = X_full.iloc[:train_n], X_full.iloc[train_n:]
y_train, y_test = y[:train_n], y[train_n:]

scalerX = StandardScaler().fit(X_train)
X_train_s, X_test_s, X_full_s = scalerX.transform(X_train), scalerX.transform(X_test), scalerX.transform(X_full)

# ---- Model ----
mc = MODEL_CHOICE['model'].lower()
if mc=='ridge': model = Ridge(alpha=MODEL_CHOICE.get('alpha',1.0))
elif mc=='lasso': model = Lasso(alpha=MODEL_CHOICE.get('alpha',0.001),max_iter=20000)
else: model = ElasticNet(alpha=MODEL_CHOICE.get('alpha',0.01),l1_ratio=MODEL_CHOICE.get('l1_ratio',0.5),max_iter=20000)
model.fit(X_train_s,y_train)

y_train_pred, y_test_pred = model.predict(X_train_s), model.predict(X_test_s)
y_full_pred = np.concatenate([y_train_pred,y_test_pred])

# ---- Metrics ----
def mape(a,b):
    a,b = np.array(a),np.array(b); mask = a!=0
    return np.mean(np.abs((a[mask]-b[mask])/a[mask]))*100 if mask.any() else np.nan

metrics = pd.DataFrame({
    "Train":[r2_score(y_train,y_train_pred)*100,
             math.sqrt(mean_squared_error(y_train,y_train_pred)),
             mape(y_train,y_train_pred),
             durbin_watson(y_train-y_train_pred)],
    "Test":[r2_score(y_test,y_test_pred)*100,
            math.sqrt(mean_squared_error(y_test,y_test_pred)),
            mape(y_test,y_test_pred),
            durbin_watson(y_test-y_test_pred)]
}, index=["R2%","RMSE","MAPE%","DW"]).T

metrics['FitWarning'] = ''
if (metrics.loc['Train','R2%']-metrics.loc['Test','R2%'])>10:
    metrics['FitWarning']="Possible Overfitting"
elif metrics.loc['Test','R2%']<50:
    metrics.loc['Test','FitWarning']="Underfitting"

from IPython.display import display
print("=== Model performance ===")
display(metrics)

# ---- Contributions ----
coefs, intercept = model.coef_, model.intercept_
contrib_matrix = X_full_s*coefs
contrib_df = pd.DataFrame(contrib_matrix,columns=feature_cols,index=df_features.index).fillna(0)
contrib_df['BASELINE'] = intercept
contrib_df['PREDICTION'] = contrib_df.sum(axis=1)
out_df = pd.DataFrame(index=df_features.index)
if WEEK_COL in df_features: out_df[WEEK_COL]=df_features[WEEK_COL]
out_df['Actual'], out_df['Predicted'] = y, y_full_pred
for c in feature_cols: out_df[c+'_contrib']=contrib_df[c].values
out_df['Base_contrib']=contrib_df['BASELINE'].values
out_df['Media_contrib']=out_df[[c+'_contrib' for c in media_all if c in feature_cols]].sum(axis=1)
out_df['Promo_contrib']=out_df[[c+'_contrib' for c in promo_vars if c in feature_cols]].sum(axis=1)
out_df['Base_vars_contrib']=out_df[[c+'_contrib' for c in base_vars if c in feature_cols]].sum(axis=1)

# ---- Plots ----
xaxis = df_features[WEEK_COL] if WEEK_COL in df_features else df_features.index

# 1) Contribution by bucket
fig=go.Figure()
fig.add_trace(go.Scatter(x=xaxis,y=out_df['Base_contrib'],stackgroup='one',name='Base'))
fig.add_trace(go.Scatter(x=xaxis,y=out_df['Media_contrib'],stackgroup='one',name='Media'))
fig.add_trace(go.Scatter(x=xaxis,y=out_df['Promo_contrib'],stackgroup='one',name='Promo'))
fig.update_layout(title="Contribution by Bucket",xaxis_title="Time",yaxis_title="Contribution")
fig.show()

# 2-4) Contributions by each variable (media, promo, base)
for m in media_all:
    if m+'_contrib' in out_df:
        fig=go.Figure(go.Scatter(x=xaxis,y=out_df[m+'_contrib'],mode='lines+markers',name=m))
        fig.update_layout(title=f"Contribution - Media: {m}")
        fig.show()
for p in promo_vars:
    if p+'_contrib' in out_df:
        fig=go.Figure(go.Scatter(x=xaxis,y=out_df[p+'_contrib'],mode='lines+markers',name=p))
        fig.update_layout(title=f"Contribution - Promo: {p}")
        fig.show()
for b in base_vars:
    if b+'_contrib' in out_df:
        fig=go.Figure(go.Scatter(x=xaxis,y=out_df[b+'_contrib'],mode='lines+markers',name=b))
        fig.update_layout(title=f"Contribution - Base: {b}")
        fig.show()

# 5) Feature importance
coef_df=pd.DataFrame({'feature':feature_cols,'coef':coefs})
coef_df['abscoef']=coef_df['coef'].abs()
coef_df=coef_df.sort_values('abscoef',ascending=False)
fig=px.bar(coef_df,x='feature',y='coef',title='Feature Coefficients',hover_data=['abscoef'])
fig.show()

# 6) Response curves for each paid media
for m in paid_media:
    maxv=max(1.0,df_features[m].max())
    grid=np.linspace(0,maxv*1.2,120); preds=[]
    for g in grid:
        row={}
        for kk in media_all+promo_vars:
            if kk==m:
                theta,beta,scale=param_store[kk]['theta'],param_store[kk]['beta'],param_store[kk]['scale']
                const=np.full(len(df_features),g)
                x_ad=adstock_geometric(const,theta) if theta else const
                x_sat=sat_1mexp(x_ad,beta) if beta else x_ad
                val=np.mean(x_sat)*(scale if scale else 1.0)
            else: val=X_trans[kk].median()
            row[kk]=val
        for bb in base_vars: row[bb]=df_features[bb].median()
        X_row=pd.DataFrame([row])[feature_cols]
        yhat=model.predict(scalerX.transform(X_row))[0]
        preds.append(yhat)
    preds=np.array(preds); ymin,ymax=preds.min(),preds.max(); eff=max(ymax-ymin,1e-9)
    mep_idx=np.argmax(preds>=(ymin+MEP_PCT*eff)); opt_idx=np.argmax(preds>=(ymin+OPT_PCT*eff))
    dydx=np.gradient(preds,grid); init_slope=dydx[1] if len(dydx)>1 else dydx[0]
    dim_idx=np.argmax(dydx<=DIM_THRESH_PCT*init_slope) if init_slope>0 else len(grid)-1
    fig=go.Figure(go.Scatter(x=grid,y=preds,mode='lines',name='Pred'))
    fig.add_trace(go.Scatter(x=[grid[mep_idx]],y=[preds[mep_idx]],mode='markers',marker=dict(color='blue',size=10),name='MEP'))
    fig.add_trace(go.Scatter(x=[grid[dim_idx]],y=[preds[dim_idx]],mode='markers',marker=dict(color='red',size=10),name='Diminishing'))
    fig.add_vrect(x0=grid[mep_idx],x1=grid[opt_idx],fillcolor="green",opacity=0.2)
    fig.update_layout(title=f"Response Curve - {m}")
    fig.show()

# 7) Actual vs Predicted (AVP) chart (FIXED: sequential weeks 1..N instead of 1970 epoch)
x_weeks = np.arange(1, len(out_df)+1)  # Week 1..122

fig=go.Figure()
fig.add_trace(go.Scatter(x=x_weeks,y=out_df['Actual'],mode='lines+markers',name='Actual'))
fig.add_trace(go.Scatter(x=x_weeks,y=out_df['Predicted'],mode='lines+markers',name='Predicted'))
fig.add_vline(x=train_n, line=dict(color='red',dash='dash'), annotation_text='Train/Test Split')
fig.update_layout(title="Actual vs Predicted (AVP)", xaxis_title="Weeks", yaxis_title=TARGET)
fig.show()

print("Done ‚Äî interactive results complete.")

# ================================================
# SCENARIO ANALYSIS MODULE
# ================================================
import pandas as pd
import numpy as np
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler

def run_scenario(data, model, scenario_changes, scaler, X_test_scaled):
    """
    Apply scenario changes and re-predict outcomes using the trained model and scaler.

    Parameters:
    data (DataFrame): The input dataframe (should be the test set, X_test).
    model: The trained regression model.
    scenario_changes (dict): A dictionary where keys are column names (variables)
                             and values are the percentage change (e.g., 0.1 for +10%).
    scaler: The StandardScaler fitted on the training data.
    X_test_scaled (DataFrame): The scaled test set used for baseline prediction.

    Returns:
    DataFrame: A DataFrame with the original data, baseline predictions, and scenario predictions.
    """
    # Ensure the index of the input data matches the index of the scaled test data
    # Also ensure we start with a clean copy to avoid modifying original X_test data unintentionally
    scenario_data = data.copy().reindex(index=X_test_scaled.index)


    # Apply changes (scale media, promos etc.)
    print("\nApplying Scenario Changes:")
    if not scenario_changes:
        print("- No scenario changes specified. Running baseline simulation.")

    for var, change in scenario_changes.items():
        # Check if the variable exists in the DataFrame
        if var in scenario_data.columns:
            scenario_data[var] *= (1 + change)   # e.g. +0.2 for +20%
            print(f"- Increased/Decreased '{var}' by {change*100:.0f}%")
        else:
            print(f"‚ö†Ô∏è Warning: Variable '{var}' not found in the data. Skipping.")

    # Ensure the column order matches the training data before scaling
    # Use the columns from the scaled training data (X_test_scaled) to ensure order and consistency
    # Reindex scenario_data to match the columns used during training/scaling and handle potential NaNs introduced by reindexing
    scenario_data_aligned = scenario_data.reindex(columns=X_test_scaled.columns, fill_value=0)


    # Scale the scenario data using the *same* scaler fitted on the training data
    try:
        # Check for NaNs before scaling and fill if any are present (e.g., fillna(0)) - robust approach
        if scenario_data_aligned.isnull().sum().sum() > 0:
            print("‚ö†Ô∏è  NaN values detected in scenario data before scaling. Filling with 0.")
            scenario_data_aligned = scenario_data_aligned.fillna(0)

        scenario_data_scaled = scaler.transform(scenario_data_aligned)
        print("‚úÖ Scenario data scaled.")
    except Exception as e:
        print(f"‚ùå Error during scaling scenario data: {e}")
        return None


    # Predict new outcome
    try:
        # Check for NaNs in scaled data before prediction as a safeguard
        if np.isnan(scenario_data_scaled).sum() > 0:
             print("‚ùå NaN values detected in scaled scenario data before prediction.")
             # You might want to return None or handle this differently
             return None

        y_pred_scenario = model.predict(scenario_data_scaled)
        # Clip predictions at 0 as sales cannot be negative
        y_pred_scenario = np.clip(y_pred_scenario, 0, None)
        print("‚úÖ Scenario predictions generated (clipped at 0).")
    except Exception as e:
         print(f"‚ùå Error during scenario prediction: {e}")
         return None


    # Get baseline prediction on the test set (assuming X_test_scaled is available)
    y_base = model.predict(X_test_scaled)
    # Clip baseline predictions at 0 as sales cannot be negative
    y_base = np.clip(y_base, 0, None)
    print("‚úÖ Baseline predictions generated (clipped at 0).")


    # Create a results DataFrame
    # Ensure the index is aligned with the predictions
    results_df = pd.DataFrame({
        'Baseline_Prediction': y_base,
        'Scenario_Prediction': y_pred_scenario
    }, index=X_test_scaled.index) # Use the index from the scaled test data


    # Calculate Lift (percentage change from baseline)
    # Avoid division by zero or NaN baseline predictions
    results_df['Sales_Lift_Pct'] = np.nan # Initialize with NaN
    valid_baseline_mask = (results_df['Baseline_Prediction'] != 0) & (~results_df['Baseline_Prediction'].isna())

    results_df.loc[valid_baseline_mask, 'Sales_Lift_Pct'] = (
        (results_df.loc[valid_baseline_mask, 'Scenario_Prediction'] - results_df.loc[valid_baseline_mask, 'Baseline_Prediction']) /
        results_df.loc[valid_baseline_mask, 'Baseline_Prediction'] * 100
    )

    print("\nüìä Scenario Analysis Results:")
    print("="*40)
    print(f"Total Baseline Sales: ‚Çπ{results_df['Baseline_Prediction'].sum():,.0f}")
    print(f"Total Scenario Sales: ‚Çπ{results_df['Scenario_Prediction'].sum():,.0f}")
    print(f"Total Sales Lift: ‚Çπ{(results_df['Scenario_Prediction'].sum() - results_df['Baseline_Prediction'].sum()):,.0f}")
    print(f"Total Sales Lift Percentage: {results_df['Sales_Lift_Pct'].mean():.2f}% (Average Weekly Lift)")


    return results_df

# --- Interactive Scenario Input ---
print("===== INTERACTIVE SCENARIO ANALYSIS =====")
print("Enter variable changes as percentage (e.g., 20 for +20%, -10 for -10%).")
print("Type 'done' to finish adding changes.")
print("Available variables for scenario testing:")

# Assuming feature_cols from the modeling cell is available
if 'feature_cols' in globals():
    for i, col in enumerate(feature_cols):
        print(f"{i+1}. {col}")
else:
    print("‚ö†Ô∏è Warning: feature_cols not found. Cannot list available variables.")
    feature_cols = X_test.columns.tolist() # Fallback to X_test columns


scenario_changes_input = {}
while True:
    try:
        user_input = input("Enter variable number and percentage change (e.g., '4 20' for 20% increase in Email Clicks) or 'done': ").strip()
        if user_input.lower() == 'done':
            break

        parts = user_input.split()
        if len(parts) == 2:
            try:
                var_index = int(parts[0]) - 1
                change_pct = float(parts[1])
                if 0 <= var_index < len(feature_cols):
                    var_name = feature_cols[var_index]
                    scenario_changes_input[var_name] = change_pct / 100.0
                    print(f"Added change: {var_name} by {change_pct:.0f}%")
                else:
                    print("‚ö†Ô∏è Invalid variable number.")
            except ValueError:
                print("‚ö†Ô∏è Invalid input format. Please use 'number percentage' or 'done'.")
        else:
            print("‚ö†Ô∏è Invalid input format. Please use 'number percentage' or 'done'.")
    except EOFError:
        print("\nInput ended. Running scenario with current changes.")
        break
    except Exception as e:
        print(f"An unexpected error occurred during input: {e}")
        break


if not scenario_changes_input:
    print("\nNo scenario changes entered. Running baseline scenario (0% change).")
    # Optionally, add a small default change or just run baseline if no changes
    # For now, we'll proceed, and the run_scenario function will handle empty changes.


# Ensure X_test, model, and scaler are available from previous cells
if 'X_test' not in globals():
    print("‚ùå ERROR: 'X_test' is not defined. Please run model preprocessing first.")
elif 'model' not in globals():
     print("‚ùå ERROR: 'model' is not defined. Please run model training first.")
elif 'scaler' not in globals():
     print("‚ùå ERROR: 'scaler' is not defined. Please run model preprocessing first.")
elif 'X_test_scaled' not in globals():
     print("‚ùå ERROR: 'X_test_scaled' is not defined. Please run model preprocessing first.")
else:
    # Run the scenario analysis
    scenario_results = run_scenario(X_test, model, scenario_changes_input, scaler, X_test_scaled)

    # Display detailed results if available
    if scenario_results is not None:
        print("\nüìã SCENARIO RESULTS DATAFRAME (first 5 rows):")
        display(scenario_results.head())

        # Optional: Plot baseline vs scenario predictions
        # Use the index of the results_df (which is the date index) for the x-axis
        plot_xaxis = scenario_results.index
        fig = go.Figure()
        fig.add_trace(go.Scatter(x=plot_xaxis, y=scenario_results['Baseline_Prediction'], mode='lines+markers', name='Baseline Prediction'))
        fig.add_trace(go.Scatter(x=plot_xaxis, y=scenario_results['Scenario_Prediction'], mode='lines+markers', name='Scenario Prediction'))
        fig.update_layout(title="Baseline vs Scenario Predictions",
                          xaxis_title="Date",
                          yaxis_title="Predicted Sales")
        fig.show()

"""# Task
Deploy the provided code to GitHub at "https://github.com/jhav5086-lab/MMM-Platform" and run it as a Streamlit application.

## Save notebook as python script

### Subtask:
Download the Colab notebook as a `.py` file.

## Create github repository

### Subtask:
Create a new public or private repository on GitHub.

## Upload code to github

### Subtask:
Upload the Python script and your data file (`Book1.csv`) to the newly created GitHub repository.

## Create `requirements.txt`

### Subtask:
Generate a `requirements.txt` file listing all the Python libraries used in your notebook.

**Reasoning**:
Create the requirements.txt file and list the necessary libraries found in the import statements.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# pandas
# numpy
# matplotlib
# seaborn
# datetime
# warnings
# sklearn
# scipy
# statsmodels
# plotly
# IPython
# difflib

"""## Modify script for streamlit

### Subtask:
Adapt the Python script to work as a Streamlit application.

**Reasoning**:
The subtask requires adapting the Python script for Streamlit, which involves removing Colab-specific commands, importing `streamlit`, and wrapping the existing logic in functions that use Streamlit widgets for user interaction and display. I will start by writing the code to remove Colab-specific commands and add the basic Streamlit structure.
"""

import streamlit as st
import pandas as pd
import numpy as np
import warnings
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import math
import difflib # Still might be useful for fuzzy matching in interactive mode

# Remove Colab-specific commands and display functions
# %store data # Removed
# %store numeric_df # Removed
# %store correlations # Removed
# %store df_features # Removed
# display() # Will be replaced by st.write/st.dataframe/st.plotly_chart


warnings.filterwarnings('ignore')

st.title("Marketing Mix Modeling (MMM) Streamlit App")

# Set up a sidebar for potential controls later
st.sidebar.title("App Controls")

# Function to convert Indian number format to float
def convert_indian_number(value):
    """Convert Indian number format string to float"""
    if isinstance(value, str):
        cleaned_value = value.replace(',', '').strip()
        if cleaned_value in ['-', ''] or cleaned_value.isspace():
            return np.nan
        try:
            return float(cleaned_value)
        except ValueError:
            # st.warning(f"Could not convert value: '{value}'") # Use st.warning for Streamlit
            return np.nan
    return value

# Wrap data loading and preprocessing
@st.cache_data
def load_and_preprocess_data(file_path):
    """Load and preprocess the marketing mix data"""
    # st.write("Loading and preprocessing data...") # Use st.write for Streamlit

    # Load the data
    data = pd.read_csv(file_path)

    all_columns = data.columns.tolist()
    date_column = 'Week_Ending'

    if date_column in all_columns:
        all_columns.remove(date_column)

    for col in all_columns:
        if data[col].dtype == 'object' and data[col].str.contains(',').any():
            data[col] = data[col].apply(convert_indian_number)
        elif data[col].dtype == 'object':
             data[col] = data[col].apply(convert_indian_number)

    if 'Paid Search Impressions' in data.columns:
        missing_count = data['Paid Search Impressions'].isna().sum()
        if missing_count > 0:
            st.warning(f"Found {missing_count} missing values in 'Paid Search Impressions'. Imputing with 0.")
            data['Paid Search Impressions'] = data['Paid Search Impressions'].fillna(0)

    if 'Week_Ending' in data.columns:
        data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%d-%m-%Y %H:%M', errors='coerce')
        data = data.sort_values('Week_Ending').reset_index(drop=True)

    # st.write("Data loading and preprocessing complete.") # Use st.write for Streamlit
    return data

# Wrap Feature Engineering
def feature_engineering_module(df):
    """
    Feature engineering module for time series data, adapted for Streamlit
    """
    st.subheader("Feature Engineering")
    df = df.copy()
    original_columns = set(df.columns)

    if 'Week_Ending' in df.columns:
        df['Week_Ending'] = pd.to_datetime(df['Week_Ending'])
        df = df.set_index('Week_Ending').sort_index()
    else:
         st.error("DataFrame must contain a 'Week_Ending' column for feature engineering.")
         return df # Return original df or handle error

    # 1. Seasonal Index (SIndex) - Using Streamlit selectbox
    st.write("##### 1. Seasonal Index")
    period_options = {
        "4 weeks (monthly pattern)": 4,
        "13 weeks (quarterly pattern)": 13,
        "26 weeks (half-yearly pattern)": 26,
        "52 weeks (yearly pattern)": 52
    }
    selected_period_label = st.selectbox(
        "Select seasonality period:",
        list(period_options.keys()),
        index=3 # Default to 52 weeks
    )
    period = period_options[selected_period_label]

    if len(df) >= 2 * period:
        try:
            decomp = seasonal_decompose(df['Sales'], period=period, model='additive', extrapolate_trend='freq')
            df['SIndex'] = decomp.seasonal
            st.success(f"‚úÖ Seasonal Index created with period={period}")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not create Seasonal Index with period {period}: {str(e)}")
    else:
        st.warning(f"‚ö†Ô∏è Not enough data points ({len(df)}) for seasonality period {period}. Skipping Seasonal Index.")


    # 2. Holiday Dummies - Using Streamlit checkbox and text input
    st.write("##### 2. Holiday Dummies")
    add_dummies = st.checkbox("Add holiday dummies?")
    if add_dummies:
        holiday_dates_str = st.text_input("Enter holiday dates (comma separated, format YYYY-MM-DD):")
        if holiday_dates_str.strip():
            dates = [d.strip() for d in holiday_dates_str.split(",") if d.strip()]
            for i, d in enumerate(dates, start=1):
                try:
                    holiday_date = pd.to_datetime(d)
                    col_name = f"Holiday_{i}"
                    df[col_name] = (df.index == holiday_date).astype(int)
                    st.success(f"‚úÖ Added dummy: {col_name} for {d}")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Could not parse date: {d}. Error: {str(e)}")
        else:
            st.info("Enter dates to add holiday dummies.")


    # 3. Split Variable - Using Streamlit checkbox, selectbox and date input
    st.write("##### 3. Split Variable")
    split_choice = st.checkbox("Split a variable at a date?")
    if split_choice:
        all_vars_for_split = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_split:
            var_to_split = st.selectbox("Select variable to split:", all_vars_for_split)
            split_date = st.date_input("Enter split date:")

            if var_to_split and split_date:
                try:
                    split_dt = pd.to_datetime(split_date)
                    df[f"{var_to_split}_pre"] = np.where(df.index <= split_dt, df[var_to_split], 0)
                    df[f"{var_to_split}_post"] = np.where(df.index > split_dt, df[var_to_split], 0)
                    df.drop(columns=[var_to_split], inplace=True)
                    st.success(f"‚úÖ Split '{var_to_split}' into '{var_to_split}_pre' and '{var_to_split}_post' at {split_dt.date()}")
                    st.info(f"Original variable '{var_to_split}' dropped.")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error splitting variable: {str(e)}")
        else:
             st.info("No suitable variables available for splitting.")


    # 4. Super Campaign - Using Streamlit checkbox and multiselect
    st.write("##### 4. Super Campaign")
    super_choice = st.checkbox("Create a super campaign?")
    if super_choice:
        all_vars_for_combine = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_combine:
            vars_to_combine = st.multiselect("Select variables to combine:", all_vars_for_combine)

            if vars_to_combine:
                custom_name_choice = st.checkbox("Provide a custom name for the super campaign?")
                if custom_name_choice:
                    super_col = st.text_input("Enter the custom name:")
                    if not super_col:
                         st.warning("Custom name cannot be empty. Using default name 'combined_var'.")
                         super_col = "combined_var"
                else:
                    super_col = "combined_var"

                if super_col in df.columns:
                     st.warning(f"Column '{super_col}' already exists. Please choose a different name or uncheck 'Provide a custom name'.")
                else:
                    try:
                        df[super_col] = df[vars_to_combine].sum(axis=1)
                        st.success(f"‚úÖ Created Super Campaign: '{super_col}' combining {vars_to_combine}")
                        df.drop(columns=vars_to_combine, inplace=True)
                        st.info(f"Original variables {vars_to_combine} dropped.")

                        # Display verification of sums
                        st.write(f"Verification of sums for '{super_col}':")
                        verification_data = []
                        for var in vars_to_combine:
                            verification_data.append({"Variable": var, "Total Sum": df[var].sum()})
                        verification_data.append({"Variable": super_col, "Total Sum": df[super_col].sum()})
                        st.dataframe(pd.DataFrame(verification_data))

                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Error creating Super Campaign: {str(e)}")
            else:
                st.info("Select variables to combine for the super campaign.")
        else:
            st.info("No suitable variables available for combining into a super campaign.")


    # Show extra features created
    new_features = sorted(set(df.columns) - original_columns)
    if new_features:
        st.subheader("üìä Extra Features Created:")
        feature_info = []
        for col in new_features:
            feature_type = "Seasonal Index" if col == "SIndex" else \
                           "Holiday Dummy" if col.startswith("Holiday_") else \
                           "Split Variable" if col.endswith(('_pre', '_post')) else \
                           "Super Campaign" if col in ['combined_var', 'Super_Campaign'] else "Other"
            feature_info.append({
                "Feature Name": col,
                "Type": feature_type,
                "Data Type": str(df[col].dtype),
                "Non-Zero Values": f"{(df[col] != 0).sum()} / {len(df)}"
            })
        st.dataframe(pd.DataFrame(feature_info))
        st.write("Sample of new features:")
        st.dataframe(df[new_features].head())
    else:
        st.info("‚ÑπÔ∏è No additional features were created.")

    return df

# Wrap Model Preprocessing
def model_preprocessing(df, feature_columns, target_column='Sales', test_size=0.2):
    """
    Preprocess data for modeling: scaling and time-based train-test split, adapted for Streamlit
    """
    st.subheader("Model Preprocessing")

    if feature_columns is None or not feature_columns:
        st.warning("No features selected for modeling.")
        return None, None, None, None, None

    X = df[feature_columns].copy()
    y = df[target_column].copy()

    st.write(f"Original feature shapes: X={X.shape}, y={y.shape}")

    # Time-based train-test split (Streamlit number input)
    st.write("##### Train-Test Split")
    test_size = st.slider("Select test set size (proportion):", min_value=0.1, max_value=0.5, value=test_size, step=0.05)
    split_idx = int(len(X) * (1 - test_size))

    X_train = X.iloc[:split_idx].copy()
    X_test = X.iloc[split_idx:].copy()
    y_train = y.iloc[:split_idx].copy()
    y_test = y.iloc[split_idx:].copy()

    st.write(f"After time-based split:")
    st.write(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
    st.write(f"y_train: {y_train.shape}, y_test: {y_test.shape}")

    # Scale the features
    st.write("##### Feature Scaling")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)

    st.success("‚úÖ Features scaled using StandardScaler")
    st.success("‚úÖ Time-based train-test split completed")

    st.write("Preview of scaled training data (first 5 rows):")
    st.dataframe(X_train_scaled.head())
    st.write("Preview of target variable (first 5 rows):")
    st.dataframe(y_train.head())

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# Wrap Model Selection and Training
def model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols):
    """
    Interactive model selection and training, adapted for Streamlit
    """
    st.subheader("Model Selection and Training")

    if X_train_scaled is None or y_train is None:
        st.warning("Missing training data. Please complete previous steps.")
        return None, None, None

    # Model Selection (Streamlit selectbox)
    model_options = {
        "ElasticNet": ElasticNet,
        "Ridge": Ridge,
        "Lasso": Lasso
    }
    selected_model_name = st.selectbox("Select Model:", list(model_options.keys()), index=0)
    model_class = model_options[selected_model_name]

    # Simple Hyperparameter Input (Streamlit number_input)
    st.write("##### Hyperparameters (simple input)")
    alpha = st.number_input("Alpha:", min_value=0.0001, value=0.01, step=0.001, format="%.4f")
    l1_ratio = None
    if selected_model_name == "ElasticNet":
        l1_ratio = st.slider("L1 Ratio (for ElasticNet):", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

    # Model reasons/notes (Streamlit text area)
    st.write("##### Model Rationale")
    reasons = st.multiselect(
        "Why this model?",
        [
            "High multicollinearity",
            "Need feature selection",
            "Balance selection & stability",
            "Small dataset",
            "Interpretability matters",
            "Sparse true drivers expected",
            "Reduce overfitting risk",
        ],
        default=["Balance selection & stability"] if selected_model_name == "ElasticNet" else []
    )
    notes = st.text_area("Additional Notes/Hypothesis:")

    # Training Button
    if st.button("Train Model"):
        st.write("Training model...")
        try:
            # Instantiate model with selected hyperparameters
            if selected_model_name == "ElasticNet":
                model = model_class(alpha=alpha, l1_ratio=l1_ratio, max_iter=20000)
            elif selected_model_name == "Lasso":
                 model = model_class(alpha=alpha, max_iter=20000)
            else: # Ridge
                 model = model_class(alpha=alpha)

            model.fit(X_train_scaled, y_train)
            st.success(f"‚úÖ Model '{selected_model_name}' trained successfully!")

            # Store model and other relevant info in session state
            st.session_state['trained_model'] = model
            st.session_state['feature_cols'] = feature_cols
            st.session_state['X_train_scaled'] = X_train_scaled
            st.session_state['X_test_scaled'] = X_test_scaled
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test

            # Display basic performance metrics after training
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            train_r2 = r2_score(y_train, y_train_pred)
            test_r2 = r2_score(y_test, y_test_pred)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

            st.write("##### Training Performance")
            st.write(f"Train R¬≤: {train_r2:.3f}")
            st.write(f"Train RMSE: {train_rmse:,.0f}")
            st.write("##### Test Performance")
            st.write(f"Test R¬≤: {test_r2:.3f}")
            st.write(f"Test RMSE: {test_rmse:,.0f}")


        except Exception as e:
            st.error(f"‚ùå Error during model training: {str(e)}")
            st.session_state['trained_model'] = None # Ensure model is None on failure

    # Return None immediately, the model will be accessed via st.session_state
    return None, None, None

# Wrap Model Evaluation and Plotting
def model_evaluation_and_plotting():
    """
    Evaluate and plot model results, adapted for Streamlit
    """
    st.subheader("Model Evaluation and Results")

    # Retrieve model and data from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_train_scaled = st.session_state.get('X_train_scaled')
    X_test_scaled = st.session_state.get('X_test_scaled')
    y_train = st.session_state.get('y_train')
    y_test = st.session_state.get('y_test')
    df_features = st.session_state.get('df_features') # Need original df for indexing/dates

    if model is None or feature_cols is None or X_train_scaled is None or X_test_scaled is None or y_train is None or y_test is None or df_features is None:
        st.info("Please train the model first.")
        return

    st.write("##### Model Performance Metrics")

    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    y_full_pred = np.concatenate([y_train_pred, y_test_pred])
    y_full_actual = np.concatenate([y_train, y_test]) # Need full actual for some metrics

    # Calculate metrics
    def mape(a,b):
        a,b = np.array(a),np.array(b); mask = a!=0
        return np.mean(np.abs((a[mask]-b[mask])/a[mask]))*100 if mask.any() else np.nan

    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    train_mape = mape(y_train, y_train_pred)
    test_mape = mape(y_test, y_test_pred)

    # Durbin-Watson for residuals on the full dataset for time series
    resid_full = y_full_actual - y_full_pred
    try:
         dw_stat = durbin_watson(resid_full)
    except:
         dw_stat = np.nan # Handle potential errors if residuals are constant etc.


    metrics_data = {
        "Metric": ["R2 (%)", "RMSE", "MAPE (%)", "Durbin-Watson (Full Residuals)"],
        "Train": [train_r2*100, train_rmse, train_mape, np.nan], # DW is for full data
        "Test": [test_r2*100, test_rmse, test_mape, np.nan] # DW is for full data
    }
    metrics_df = pd.DataFrame(metrics_data)

    # Add DW stat separately or to a combined row
    metrics_df.loc[metrics_df['Metric'] == "Durbin-Watson (Full Residuals)", ['Train', 'Test']] = dw_stat # Display in both columns or adjust table structure

    st.dataframe(metrics_df.set_index('Metric'))

    # Fit Warning
    fit_warning = ""
    if (train_r2*100 - test_r2*100) > 10:
        fit_warning="Possible Overfitting"
    elif test_r2*100 < 50:
        fit_warning="Underfitting"
    if fit_warning:
        st.warning(f"Fit Warning: {fit_warning}")

    # Contributions Calculation (re-calculate as it wasn't stored globally)
    coefs = model.coef_
    intercept = model.intercept_
    contrib_matrix = X_train_scaled.values * coefs # Calculate on training set for average contribution interpretation
    contrib_df_train = pd.DataFrame(contrib_matrix, columns=feature_cols, index=X_train_scaled.index).fillna(0)
    contrib_df_train['BASELINE'] = intercept

    # Calculate average contributions
    avg_contrib = contrib_df_train.mean().sort_values(ascending=False)
    st.write("##### Average Feature Contributions (on Training Data)")
    st.dataframe(avg_contrib.to_frame("Average Contribution"))

    # Contributions over Time (using full scaled data X_full_s if available)
    scaler = StandardScaler().fit(X_train_scaled) # Refit scaler on training data
    X_full = pd.concat([st.session_state.get('X_train_scaled_original'), st.session_state.get('X_test_scaled_original')]) # Assuming original unscaled X_train/X_test are needed
    # Need the original features DataFrame before scaling, not scaled versions
    # Let's retrieve the full original features dataframe used *before* scaling
    X_full_original = pd.concat([st.session_state['X_train_original'], st.session_state['X_test_original']]) # Assuming these are stored

    # Re-scale the full original data for consistent contribution calculation
    X_full_scaled = scaler.transform(X_full_original[feature_cols])
    X_full_scaled_df = pd.DataFrame(X_full_scaled, columns=feature_cols, index=X_full_original.index)

    contrib_matrix_full = X_full_scaled_df.values * coefs
    contrib_df_full = pd.DataFrame(contrib_matrix_full, columns=feature_cols, index=X_full_scaled_df.index).fillna(0)
    contrib_df_full['BASELINE'] = intercept
    contrib_df_full['PREDICTION'] = contrib_df_full.sum(axis=1)

    # Bucket contributions (Need definitions of media_all, promo_vars, base_vars)
    # Let's try to infer buckets based on feature_cols or use a default if needed
    # This part might need manual adjustment or a more robust bucketing in Streamlit flow
    media_all = [c for c in feature_cols if any(k in c.lower() for k in ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']) and 'organic' not in c.lower()]
    promo_vars = [c for c in feature_cols if any(k in c.lower() for k in ['discount', 'promo', 'promotion', 'offer'])]
    base_vars = [c for c in feature_cols if c not in media_all + promo_vars]

    contrib_df_full['Media_contrib'] = contrib_df_full[[c for c in media_all if c in feature_cols]].sum(axis=1)
    contrib_df_full['Promo_contrib'] = contrib_df_full[[c for c in promo_vars if c in feature_cols]].sum(axis=1)
    contrib_df_full['Base_vars_contrib'] = contrib_df_full[[c for c in base_vars if c in feature_cols]].sum(axis=1)


    st.write("##### Contribution by Bucket Over Time")
    fig_bucket_contrib = go.Figure()
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Base_vars_contrib'], stackgroup='one', name='Base'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Media_contrib'], stackgroup='one', name='Media'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Promo_contrib'], stackgroup='one', name='Promo'))
    fig_bucket_contrib.update_layout(title="Contribution by Bucket",xaxis_title="Time",yaxis_title="Contribution")
    st.plotly_chart(fig_bucket_contrib)

    # Contributions by each variable (Media, Promo, Base) - example for Media
    st.write("##### Individual Variable Contributions Over Time")
    selected_bucket_for_plot = st.selectbox("Select bucket to plot individual contributions:", ["Media", "Promo", "Base"])

    if selected_bucket_for_plot == "Media":
        vars_to_plot = [c for c in media_all if c in feature_cols]
    elif selected_bucket_for_plot == "Promo":
        vars_to_plot = [c for c in promo_vars if c in feature_cols]
    else: # Base
        vars_to_plot = [c for c in base_vars if c in feature_cols]

    for var in vars_to_plot:
        if var + '_contrib' in contrib_df_full.columns:
            fig_var_contrib = go.Figure(go.Scatter(x=contrib_df_full.index, y=contrib_df_full[var+'_contrib'], mode='lines+markers', name=var))
            fig_var_contrib.update_layout(title=f"Contribution - {selected_bucket_for_plot}: {var}")
            st.plotly_chart(fig_var_contrib)


    # Feature importance (Coefficients)
    st.write("##### Feature Importance (Model Coefficients)")
    coef_df = pd.DataFrame({'feature': feature_cols, 'coef': coefs})
    coef_df['abscoef'] = coef_df['coef'].abs()
    coef_df = coef_df.sort_values('abscoef', ascending=False)
    fig_coef = px.bar(coef_df, x='feature', y='coef', title='Feature Coefficients', hover_data=['abscoef'])
    st.plotly_chart(fig_coef)

    # Response curves for each paid media (Need paid_media list and param_store)
    # Re-calculate paid_media and param_store based on feature_cols and df_features
    paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
    paid_media = [c for c in feature_cols if any(k in c.lower() for k in paid_keywords) and 'organic' not in c.lower()]

    # Re-calculate adstock/saturation parameters on the full original data
    param_store = {}
    ADSTOCK_DEFAULT_THETA = 0.4
    SAT_DEFAULT_BETA = 1e-6
    def adstock_geometric(x, theta):
        out = np.zeros_like(x, dtype=float)
        for t in range(len(x)):
            out[t] = x[t] + (theta*out[t-1] if t>0 else x[t])
        return out

    def sat_1mexp(x, beta):
        return 1.0 - np.exp(-beta * np.clip(x,0,None))

    def auto_theta(series):
        s = pd.Series(series).fillna(0.0)
        if len(s)<3 or s.std()==0: return ADSTOCK_DEFAULT_THETA
        ac1 = s.autocorr(lag=1)
        return float(np.clip(ac1 if not pd.isna(ac1) else ADSTOCK_DEFAULT_THETA, 0.0,0.9))

    def auto_beta(x_ad):
        med = np.median(x_ad[x_ad>0]) if np.any(x_ad>0) else 0.0
        return float(np.log(2.0)/(med+1e-12)) if med>0 else SAT_DEFAULT_BETA

    X_trans_full = pd.DataFrame(index=df_features.index) # Use df_features for original data
    for c in feature_cols:
        if c in df_features.columns: # Ensure column exists in original df
            raw = df_features[c].fillna(0.0).astype(float).values
            if c in paid_media:
                theta = auto_theta(raw) # Use auto_theta for simplicity in Streamlit
                beta = auto_beta(adstock_geometric(raw, theta)) # Use auto_beta
                x_ad = adstock_geometric(raw, theta)
                x_sat = sat_1mexp(x_ad, beta)
                scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
                x_final = x_sat*scale
                param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
            else:
                x_final = raw
                param_store[c] = {"theta":None,"beta":None,"scale":1.0} # Store None for non-paid media
            X_trans_full[c] = x_final
        else:
             st.warning(f"Original column '{c}' not found in df_features for transformation.")


    st.write("##### Response Curves for Paid Media")
    MEP_PCT = 0.05
    OPT_PCT = 0.80
    DIM_THRESH_PCT = 0.01

    # Need the scaler fitted on the *training* data for prediction
    scaler = StandardScaler().fit(st.session_state['X_train_original'][feature_cols])


    for m in paid_media:
        if m in df_features.columns and m in param_store: # Ensure media var exists and params were stored
            maxv = max(1.0, df_features[m].max()) # Use original df_features for max value
            grid = np.linspace(0, maxv * 1.2, 120)
            preds = []

            # Get median values for other variables from the training data
            median_row_train = st.session_state['X_train_original'][feature_cols].median().to_dict()

            for g in grid:
                row = median_row_train.copy() # Start with median values
                # Apply adstock and saturation to the current variable 'g'
                theta = param_store[m]['theta']
                beta = param_store[m]['beta']
                scale = param_store[m]['scale']

                # Create a temporary series for adstock calculation
                temp_series = pd.Series(np.full(len(df_features), g)) # Use full length for consistent adstock
                x_ad = adstock_geometric(temp_series.values, theta) if theta is not None else temp_series.values # Use .values
                x_sat = sat_1mexp(x_ad, beta) if beta is not None else x_ad
                val = np.mean(x_sat) * (scale if scale is not None else 1.0)

                row[m] = val # Set the value for the current variable

                # Need to handle other media/promo/base variables that might have transforms
                # For simplicity in response curve, we assume other variables are at their median *untransformed* value
                # and then apply the same scaling as the training data.
                # A more rigorous approach would re-apply all transforms for each grid point, but this is complex.
                # Let's use the median of the *transformed* training data for other variables.
                median_row_transformed_train = X_train_scaled.median().to_dict()
                row_transformed = median_row_transformed_train.copy()
                row_transformed[m] = scaler.transform(np.array([[g]]))[0][0] # Scale the current grid value directly

                X_row_scaled = pd.DataFrame([row_transformed], columns=feature_cols) # Use scaled median for others

                try:
                    # Predict using the scaled row
                    yhat = model.predict(X_row_scaled)[0]
                    preds.append(yhat)
                except Exception as predict_e:
                    st.warning(f"Error predicting for {m} response curve at value {g}: {predict_e}")
                    preds.append(np.nan) # Append NaN on error

            preds = np.array(preds)
            preds = np.clip(preds, 0, None) # Clip predictions at 0

            ymin, ymax = preds.min(), preds.max()
            eff = max(ymax - ymin, 1e-9)

            # Avoid errors if predictions are all the same (eff is tiny)
            if eff > 1e-9:
                mep_idx = np.argmax(preds >= (ymin + MEP_PCT * eff))
                opt_idx = np.argmax(preds >= (ymin + OPT_PCT * eff))
                dydx = np.gradient(preds, grid)
                init_slope = dydx[1] if len(dydx) > 1 else dydx[0]

                if init_slope > 0:
                    # Find index where slope drops below threshold
                    # Handle case where dydx might have NaNs or be non-positive
                    valid_slopes_idx = np.where(dydx > 0)[0]
                    if valid_slopes_idx.size > 1:
                        dim_check = dydx[valid_slopes_idx] <= DIM_THRESH_PCT * init_slope
                        dim_indices = valid_slopes_idx[dim_check]
                        dim_idx = dim_indices[0] if dim_indices.size > 0 else len(grid) - 1
                    else:
                        dim_idx = len(grid) - 1 # If no positive slopes or only one, diminishing point is the end
                else:
                     dim_idx = len(grid) - 1 # If initial slope is zero or negative, diminishing point is the end


                fig = go.Figure(go.Scatter(x=grid, y=preds, mode='lines', name='Pred'))
                fig.add_trace(go.Scatter(x=[grid[mep_idx]], y=[preds[mep_idx]], mode='markers', marker=dict(color='blue', size=10), name='MEP'))
                fig.add_trace(go.Scatter(x=[grid[dim_idx]], y=[preds[dim_idx]], mode='markers', marker=dict(color='red', size=10), name='Diminishing'))
                fig.add_vrect(x0=grid[mep_idx], x1=grid[opt_idx], fillcolor="green", opacity=0.2, name='Optimal Range')
                fig.update_layout(title=f"Response Curve - {m}", xaxis_title=m, yaxis_title="Predicted Sales")
                st.plotly_chart(fig)
            else:
                 st.info(f"Skipping response curve for {m}: Predictions are constant or have no variation.")


    # Actual vs Predicted (AVP) chart
    st.write("##### Actual vs Predicted (AVP)")
    # Use the index from the full actual/predicted data for plotting
    plot_xaxis = df_features.index # Use original df_features index for dates

    fig_avp = go.Figure()
    fig_avp.add_trace(go.Scatter(x=plot_xaxis, y=y_full_actual, mode='lines+markers', name='Actual'))
    fig_avp.add_trace(go.Scatter(x=plot_xaxis, y=y_full_pred, mode='lines+markers', name='Predicted'))

    # Find the date corresponding to the train/test split index
    train_n = len(y_train)
    if train_n < len(plot_xaxis):
         split_date = plot_xaxis[train_n - 1] # Date of the last training point
         fig_avp.add_vline(x=split_date, line=dict(color='red', dash='dash'), annotation_text='Train/Test Split')

    fig_avp.update_layout(title="Actual vs Predicted (AVP)", xaxis_title="Date", yaxis_title="Sales")
    st.plotly_chart(fig_avp)


# Wrap Scenario Analysis Module
def scenario_analysis_module():
    """
    Scenario analysis module, adapted for Streamlit
    """
    st.subheader("Scenario Analysis")

    # Retrieve model, data, and scaler from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_test_scaled = st.session_state.get('X_test_scaled')
    X_test_original = st.session_state.get('X_test_original') # Need original test data for scenario changes
    scaler = st.session_state.get('scaler') # Need the fitted scaler

    if model is None or feature_cols is None or X_test_scaled is None or X_test_original is None or scaler is None:
        st.info("Please train the model first to run scenario analysis.")
        return

    st.write("##### Create a Scenario")
    st.write("Modify the variables in the sidebar to see the predicted impact on sales.")

    scenario_changes = {}

    # Use sidebar for scenario inputs
    st.sidebar.subheader("Scenario Inputs (% Change)")
    st.sidebar.write("Enter percentage change (e.g., 20 for +20%, -10 for -10%).")

    # Dynamically create number inputs for each feature in the sidebar
    if feature_cols:
        for col in feature_cols:
            # Use a unique key for each widget
            change_pct = st.sidebar.number_input(f"{col}:", value=0.0, step=1.0, format="%.1f", key=f"scenario_{col}_change")
            scenario_changes[col] = change_pct / 100.0 # Store as proportion


    if st.button("Run Scenario"):
        st.write("Running scenario...")
        try:
            # Use the original test data as the base for the scenario
            scenario_results = run_scenario(X_test_original, model, scenario_changes, scaler, X_test_scaled)

            if scenario_results is not None:
                st.write("##### Scenario Analysis Results")
                total_baseline_sales = scenario_results['Baseline_Prediction'].sum()
                total_scenario_sales = scenario_results['Scenario_Prediction'].sum()
                total_sales_lift = total_scenario_sales - total_baseline_sales
                avg_sales_lift_pct = scenario_results['Sales_Lift_Pct'].mean()

                st.write(f"**Total Baseline Sales (Test Period):** ‚Çπ{total_baseline_sales:,.0f}")
                st.write(f"**Total Scenario Sales (Test Period):** ‚Çπ{total_scenario_sales:,.0f}")
                st.write(f"**Total Sales Lift (Test Period):** ‚Çπ{total_sales_lift:,.0f}")
                st.write(f"**Average Weekly Sales Lift Percentage:** {avg_sales_lift_pct:.2f}%")

                st.write("Detailed results (first 5 rows):")
                st.dataframe(scenario_results.head())

                # Plot Baseline vs Scenario Predictions
                plot_xaxis = scenario_results.index
                fig_scenario = go.Figure()
                fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=scenario_results['Baseline_Prediction'], mode='lines+markers', name='Baseline Prediction'))
                fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=scenario_results['Scenario_Prediction'], mode='lines+markers', name='Scenario Prediction'))
                fig_scenario.update_layout(title="Baseline vs Scenario Predictions",
                                          xaxis_title="Date",
                                          yaxis_title="Predicted Sales")
                st.plotly_chart(fig_scenario)
            else:
                st.warning("Scenario analysis could not be completed.")

        except Exception as e:
            st.error(f"‚ùå An error occurred during scenario execution: {str(e)}")


# --- Main Streamlit App Flow ---
def main():
    """
    Main function to run the Streamlit MMM application.
    """
    st.sidebar.header("File Upload")
    uploaded_file = st.sidebar.file_uploader("Upload your CSV file", type=["csv"])

    df = None
    if uploaded_file is not None:
        # Load and preprocess data
        df = load_and_preprocess_data(uploaded_file)
        st.session_state['original_data'] = df.copy() # Store original data

        st.subheader("Raw Data Preview")
        st.write(f"Shape: {df.shape}")
        st.dataframe(df.head())

        # Perform EDA (Optional - can be added as a separate section if needed)
        # st.subheader("Exploratory Data Analysis (EDA)")
        # Note: Comprehensive EDA plots might be too many for a basic Streamlit app.
        # Consider adding key EDA plots selectively or on demand.

        # Check if data loading was successful and has required columns
        if df is not None and 'Sales' in df.columns and 'Week_Ending' in df.columns:

            # Feature Engineering
            df_features = feature_engineering_module(df.copy())
            st.session_state['df_features'] = df_features.copy() # Store df with features

            # Define feature columns for modeling (exclude date and target)
            feature_cols = [col for col in df_features.columns if col not in ['Week_Ending', 'Sales'] and col is not None]

            if feature_cols:
                 # Model Preprocessing
                 st.write("---") # Separator
                 X_train_scaled, X_test_scaled, y_train, y_test, scaler = model_preprocessing(
                     df_features,
                     feature_cols,
                     target_column='Sales'
                 )

                 # Store preprocessing results in session state
                 st.session_state['feature_cols'] = feature_cols
                 st.session_state['X_train_scaled'] = X_train_scaled
                 st.session_state['X_test_scaled'] = X_test_scaled
                 st.session_state['y_train'] = y_train
                 st.session_state['y_test'] = y_test
                 st.session_state['scaler'] = scaler
                 # Store original train/test splits for scenario analysis base
                 st.session_state['X_train_original'] = df_features[feature_cols].iloc[:len(y_train)].copy()
                 st.session_state['X_test_original'] = df_features[feature_cols].iloc[len(y_train):].copy()


                 # Model Selection and Training
                 st.write("---") # Separator
                 model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols)

                 # Model Evaluation and Plotting (only run if model is trained)
                 if st.session_state.get('trained_model') is not None:
                      st.write("---") # Separator
                      model_evaluation_and_plotting()

                 # Scenario Analysis (only run if model is trained)
                 if st.session_state.get('trained_model') is not None:
                      st.write("---") # Separator
                      scenario_analysis_module()


            else:
                 st.warning("No features available for modeling after preprocessing.")
        else:
            if uploaded_file is not None:
                 st.error("Uploaded file does not contain 'Sales' or 'Week_Ending' columns, or data loading failed.")

    else:
        st.info("Please upload a CSV file to get started.")

# Run the main function
if __name__ == "__main__":
    main()

"""**Reasoning**:
The previous command failed because the `streamlit` module was not found. I need to install `streamlit`. I will use `pip` to install it in a separate cell.


"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install streamlit

"""**Reasoning**:
I have successfully installed streamlit. Now I will re-execute the previous code block that adapts the Python script for Streamlit, as it was the correct approach but failed due to the missing library.


"""

import streamlit as st
import pandas as pd
import numpy as np
import warnings
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import math
import difflib # Still might be useful for fuzzy matching in interactive mode


warnings.filterwarnings('ignore')

st.title("Marketing Mix Modeling (MMM) Streamlit App")

# Set up a sidebar for potential controls later
st.sidebar.title("App Controls")

# Function to convert Indian number format to float
def convert_indian_number(value):
    """Convert Indian number format string to float"""
    if isinstance(value, str):
        cleaned_value = value.replace(',', '').strip()
        if cleaned_value in ['-', ''] or cleaned_value.isspace():
            return np.nan
        try:
            return float(cleaned_value)
        except ValueError:
            # st.warning(f"Could not convert value: '{value}'") # Use st.warning for Streamlit
            return np.nan
    return value

# Wrap data loading and preprocessing
@st.cache_data
def load_and_preprocess_data(file_path):
    """Load and preprocess the marketing mix data"""
    # st.write("Loading and preprocessing data...") # Use st.write for Streamlit

    # Load the data
    data = pd.read_csv(file_path)

    all_columns = data.columns.tolist()
    date_column = 'Week_Ending'

    if date_column in all_columns:
        all_columns.remove(date_column)

    for col in all_columns:
        if data[col].dtype == 'object' and data[col].str.contains(',').any():
            data[col] = data[col].apply(convert_indian_number)
        elif data[col].dtype == 'object':
             data[col] = data[col].apply(convert_indian_number)

    if 'Paid Search Impressions' in data.columns:
        missing_count = data['Paid Search Impressions'].isna().sum()
        if missing_count > 0:
            st.warning(f"Found {missing_count} missing values in 'Paid Search Impressions'. Imputing with 0.")
            data['Paid Search Impressions'] = data['Paid Search Impressions'].fillna(0)

    if 'Week_Ending' in data.columns:
        data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%d-%m-%Y %H:%M', errors='coerce')
        data = data.sort_values('Week_Ending').reset_index(drop=True)

    # st.write("Data loading and preprocessing complete.") # Use st.write for Streamlit
    return data

# Wrap Feature Engineering
def feature_engineering_module(df):
    """
    Feature engineering module for time series data, adapted for Streamlit
    """
    st.subheader("Feature Engineering")
    df = df.copy()
    original_columns = set(df.columns)

    if 'Week_Ending' in df.columns:
        df['Week_Ending'] = pd.to_datetime(df['Week_Ending'])
        df = df.set_index('Week_Ending').sort_index()
    else:
         st.error("DataFrame must contain a 'Week_Ending' column for feature engineering.")
         return df # Return original df or handle error

    # 1. Seasonal Index (SIndex) - Using Streamlit selectbox
    st.write("##### 1. Seasonal Index")
    period_options = {
        "4 weeks (monthly pattern)": 4,
        "13 weeks (quarterly pattern)": 13,
        "26 weeks (half-yearly pattern)": 26,
        "52 weeks (yearly pattern)": 52
    }
    selected_period_label = st.selectbox(
        "Select seasonality period:",
        list(period_options.keys()),
        index=3 # Default to 52 weeks
    )
    period = period_options[selected_period_label]

    if len(df) >= 2 * period:
        try:
            decomp = seasonal_decompose(df['Sales'], period=period, model='additive', extrapolate_trend='freq')
            df['SIndex'] = decomp.seasonal
            st.success(f"‚úÖ Seasonal Index created with period={period}")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not create Seasonal Index with period {period}: {str(e)}")
    else:
        st.warning(f"‚ö†Ô∏è Not enough data points ({len(df)}) for seasonality period {period}. Skipping Seasonal Index.")


    # 2. Holiday Dummies - Using Streamlit checkbox and text input
    st.write("##### 2. Holiday Dummies")
    add_dummies = st.checkbox("Add holiday dummies?")
    if add_dummies:
        holiday_dates_str = st.text_input("Enter holiday dates (comma separated, format YYYY-MM-DD):")
        if holiday_dates_str.strip():
            dates = [d.strip() for d in holiday_dates_str.split(",") if d.strip()]
            for i, d in enumerate(dates, start=1):
                try:
                    holiday_date = pd.to_datetime(d)
                    col_name = f"Holiday_{i}"
                    df[col_name] = (df.index == holiday_date).astype(int)
                    st.success(f"‚úÖ Added dummy: {col_name} for {d}")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Could not parse date: {d}. Error: {str(e)}")
        else:
            st.info("Enter dates to add holiday dummies.")


    # 3. Split Variable - Using Streamlit checkbox, selectbox and date input
    st.write("##### 3. Split Variable")
    split_choice = st.checkbox("Split a variable at a date?")
    if split_choice:
        all_vars_for_split = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_split:
            var_to_split = st.selectbox("Select variable to split:", all_vars_for_split)
            split_date = st.date_input("Enter split date:")

            if var_to_split and split_date:
                try:
                    split_dt = pd.to_datetime(split_date)
                    df[f"{var_to_split}_pre"] = np.where(df.index <= split_dt, df[var_to_split], 0)
                    df[f"{var_to_split}_post"] = np.where(df.index > split_dt, df[var_to_split], 0)
                    df.drop(columns=[var_to_split], inplace=True)
                    st.success(f"‚úÖ Split '{var_to_split}' into '{var_to_split}_pre' and '{var_to_split}_post' at {split_dt.date()}")
                    st.info(f"Original variable '{var_to_split}' dropped.")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error splitting variable: {str(e)}")
        else:
             st.info("No suitable variables available for splitting.")


    # 4. Super Campaign - Using Streamlit checkbox and multiselect
    st.write("##### 4. Super Campaign")
    super_choice = st.checkbox("Create a super campaign?")
    if super_choice:
        all_vars_for_combine = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_combine:
            vars_to_combine = st.multiselect("Select variables to combine:", all_vars_for_combine)

            if vars_to_combine:
                custom_name_choice = st.checkbox("Provide a custom name for the super campaign?")
                if custom_name_choice:
                    super_col = st.text_input("Enter the custom name:")
                    if not super_col:
                         st.warning("Custom name cannot be empty. Using default name 'combined_var'.")
                         super_col = "combined_var"
                else:
                    super_col = "combined_var"

                if super_col in df.columns:
                     st.warning(f"Column '{super_col}' already exists. Please choose a different name or uncheck 'Provide a custom name'.")
                else:
                    try:
                        df[super_col] = df[vars_to_combine].sum(axis=1)
                        st.success(f"‚úÖ Created Super Campaign: '{super_col}' combining {vars_to_combine}")
                        df.drop(columns=vars_to_combine, inplace=True)
                        st.info(f"Original variables {vars_to_combine} dropped.")

                        # Display verification of sums
                        st.write(f"Verification of sums for '{super_col}':")
                        verification_data = []
                        for var in vars_to_combine:
                            verification_data.append({"Variable": var, "Total Sum": df[var].sum()})
                        verification_data.append({"Variable": super_col, "Total Sum": df[super_col].sum()})
                        st.dataframe(pd.DataFrame(verification_data))

                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Error creating Super Campaign: {str(e)}")
            else:
                st.info("Select variables to combine for the super campaign.")
        else:
            st.info("No suitable variables available for combining into a super campaign.")


    # Show extra features created
    new_features = sorted(set(df.columns) - original_columns)
    if new_features:
        st.subheader("üìä Extra Features Created:")
        feature_info = []
        for col in new_features:
            feature_type = "Seasonal Index" if col == "SIndex" else \
                           "Holiday Dummy" if col.startswith("Holiday_") else \
                           "Split Variable" if col.endswith(('_pre', '_post')) else \
                           "Super Campaign" if col in ['combined_var', 'Super_Campaign'] else "Other"
            feature_info.append({
                "Feature Name": col,
                "Type": feature_type,
                "Data Type": str(df[col].dtype),
                "Non-Zero Values": f"{(df[col] != 0).sum()} / {len(df)}"
            })
        st.dataframe(pd.DataFrame(feature_info))
        st.write("Sample of new features:")
        st.dataframe(df[new_features].head())
    else:
        st.info("‚ÑπÔ∏è No additional features were created.")

    return df

# Wrap Model Preprocessing
def model_preprocessing(df, feature_columns, target_column='Sales', test_size=0.2):
    """
    Preprocess data for modeling: scaling and time-based train-test split, adapted for Streamlit
    """
    st.subheader("Model Preprocessing")

    if feature_columns is None or not feature_columns:
        st.warning("No features selected for modeling.")
        return None, None, None, None, None

    X = df[feature_columns].copy()
    y = df[target_column].copy()

    st.write(f"Original feature shapes: X={X.shape}, y={y.shape}")

    # Time-based train-test split (Streamlit number input)
    st.write("##### Train-Test Split")
    test_size = st.slider("Select test set size (proportion):", min_value=0.1, max_value=0.5, value=test_size, step=0.05)
    split_idx = int(len(X) * (1 - test_size))

    X_train = X.iloc[:split_idx].copy()
    X_test = X.iloc[split_idx:].copy()
    y_train = y.iloc[:split_idx].copy()
    y_test = y.iloc[split_idx:].copy()

    st.write(f"After time-based split:")
    st.write(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
    st.write(f"y_train: {y_train.shape}, y_test: {y_test.shape}")

    # Scale the features
    st.write("##### Feature Scaling")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)

    st.success("‚úÖ Features scaled using StandardScaler")
    st.success("‚úÖ Time-based train-test split completed")

    st.write("Preview of scaled training data (first 5 rows):")
    st.dataframe(X_train_scaled.head())
    st.write("Preview of target variable (first 5 rows):")
    st.dataframe(y_train.head())

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# Wrap Model Selection and Training
def model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols):
    """
    Interactive model selection and training, adapted for Streamlit
    """
    st.subheader("Model Selection and Training")

    if X_train_scaled is None or y_train is None:
        st.warning("Missing training data. Please complete previous steps.")
        return None, None, None

    # Model Selection (Streamlit selectbox)
    model_options = {
        "ElasticNet": ElasticNet,
        "Ridge": Ridge,
        "Lasso": Lasso
    }
    selected_model_name = st.selectbox("Select Model:", list(model_options.keys()), index=0)
    model_class = model_options[selected_model_name]

    # Simple Hyperparameter Input (Streamlit number_input)
    st.write("##### Hyperparameters (simple input)")
    alpha = st.number_input("Alpha:", min_value=0.0001, value=0.01, step=0.001, format="%.4f")
    l1_ratio = None
    if selected_model_name == "ElasticNet":
        l1_ratio = st.slider("L1 Ratio (for ElasticNet):", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

    # Model reasons/notes (Streamlit text area)
    st.write("##### Model Rationale")
    reasons = st.multiselect(
        "Why this model?",
        [
            "High multicollinearity",
            "Need feature selection",
            "Balance selection & stability",
            "Small dataset",
            "Interpretability matters",
            "Sparse true drivers expected",
            "Reduce overfitting risk",
        ],
        default=["Balance selection & stability"] if selected_model_name == "ElasticNet" else []
    )
    notes = st.text_area("Additional Notes/Hypothesis:")

    # Training Button
    if st.button("Train Model"):
        st.write("Training model...")
        try:
            # Instantiate model with selected hyperparameters
            if selected_model_name == "ElasticNet":
                model = model_class(alpha=alpha, l1_ratio=l1_ratio, max_iter=20000)
            elif selected_model_name == "Lasso":
                 model = model_class(alpha=alpha, max_iter=20000)
            else: # Ridge
                 model = model_class(alpha=alpha)

            model.fit(X_train_scaled, y_train)
            st.success(f"‚úÖ Model '{selected_model_name}' trained successfully!")

            # Store model and other relevant info in session state
            st.session_state['trained_model'] = model
            st.session_state['feature_cols'] = feature_cols
            st.session_state['X_train_scaled'] = X_train_scaled
            st.session_state['X_test_scaled'] = X_test_scaled
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test
            # Store original train/test splits for scenario analysis base (if not already stored)
            if 'X_train_original' not in st.session_state or 'X_test_original' not in st.session_state:
                 st.warning("Original train/test data not found in session state. Scenario analysis might be limited.")
                 # Attempt to reconstruct if possible, or skip scenario analysis later
                 if 'df_features' in st.session_state and 'y_train' in st.session_state:
                      train_n = len(st.session_state['y_train'])
                      all_features = [col for col in st.session_state['df_features'].columns if col not in ['Week_Ending', 'Sales']]
                      st.session_state['X_train_original'] = st.session_state['df_features'][all_features].iloc[:train_n].copy()
                      st.session_state['X_test_original'] = st.session_state['df_features'][all_features].iloc[train_n:].copy()
                      st.info("Attempted to reconstruct original train/test data from df_features.")
                 else:
                      st.error("Cannot reconstruct original train/test data. Scenario analysis will not be available.")
                      st.session_state['X_train_original'] = None
                      st.session_state['X_test_original'] = None


            # Display basic performance metrics after training
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            train_r2 = r2_score(y_train, y_train_pred)
            test_r2 = r2_score(y_test, y_test_pred)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

            st.write("##### Training Performance")
            st.write(f"Train R¬≤: {train_r2:.3f}")
            st.write(f"Train RMSE: {train_rmse:,.0f}")
            st.write("##### Test Performance")
            st.write(f"Test R¬≤: {test_r2:.3f}")
            st.write(f"Test RMSE: {test_rmse:,.0f}")


        except Exception as e:
            st.error(f"‚ùå Error during model training: {str(e)}")
            st.session_state['trained_model'] = None # Ensure model is None on failure

    # Return None immediately, the model will be accessed via st.session_state
    return None, None, None # Returning model, coefficients, intercept might be confusing with session state

# Wrap Model Evaluation and Plotting
def model_evaluation_and_plotting():
    """
    Evaluate and plot model results, adapted for Streamlit
    """
    st.subheader("Model Evaluation and Results")

    # Retrieve model and data from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_train_scaled = st.session_state.get('X_train_scaled')
    X_test_scaled = st.session_state.get('X_test_scaled')
    y_train = st.session_state.get('y_train')
    y_test = st.session_state.get('y_test')
    df_features = st.session_state.get('df_features') # Need original df for indexing/dates
    X_train_original = st.session_state.get('X_train_original') # Need original train data for scaling
    X_test_original = st.session_state.get('X_test_original') # Need original test data for scaling

    if model is None or feature_cols is None or X_train_scaled is None or X_test_scaled is None or y_train is None or y_test is None or df_features is None or X_train_original is None or X_test_original is None:
        st.info("Please train the model first.")
        return

    st.write("##### Model Performance Metrics")

    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    y_full_pred = np.concatenate([y_train_pred, y_test_pred])
    y_full_actual = np.concatenate([y_train, y_test]) # Need full actual for some metrics

    # Calculate metrics
    def mape(a,b):
        a,b = np.array(a),np.array(b); mask = a!=0
        return np.mean(np.abs((a[mask]-b[mask])/a[mask]))*100 if mask.any() else np.nan

    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    train_mape = mape(y_train, y_train_pred)
    test_mape = mape(y_test, y_test_pred)

    # Durbin-Watson for residuals on the full dataset for time series
    resid_full = y_full_actual - y_full_pred
    try:
         dw_stat = durbin_watson(resid_full)
    except:
         dw_stat = np.nan # Handle potential errors if residuals are constant etc.


    metrics_data = {
        "Metric": ["R2 (%)", "RMSE", "MAPE (%)", "Durbin-Watson (Full Residuals)"],
        "Train": [train_r2*100, train_rmse, train_mape, np.nan], # DW is for full data
        "Test": [test_r2*100, test_rmse, test_mape, np.nan] # DW is for full data
    }
    metrics_df = pd.DataFrame(metrics_data)

    # Add DW stat separately or to a combined row
    metrics_df.loc[metrics_df['Metric'] == "Durbin-Watson (Full Residuals)", ['Train', 'Test']] = dw_stat # Display in both columns or adjust table structure

    st.dataframe(metrics_df.set_index('Metric'))

    # Fit Warning
    fit_warning = ""
    if (train_r2*100 - test_r2*100) > 10:
        fit_warning="Possible Overfitting"
    elif test_r2*100 < 50:
        fit_warning="Underfitting"
    if fit_warning:
        st.warning(f"Fit Warning: {fit_warning}")

    # Contributions Calculation (re-calculate as it wasn't stored globally)
    coefs = model.coef_
    intercept = model.intercept_
    # Calculate on training set for average contribution interpretation
    contrib_matrix = X_train_scaled.values * coefs
    contrib_df_train = pd.DataFrame(contrib_matrix, columns=feature_cols, index=X_train_scaled.index).fillna(0)
    contrib_df_train['BASELINE'] = intercept

    # Calculate average contributions
    avg_contrib = contrib_df_train.mean().sort_values(ascending=False)
    st.write("##### Average Feature Contributions (on Training Data)")
    st.dataframe(avg_contrib.to_frame("Average Contribution"))

    # Contributions over Time (using full scaled data X_full_s if available)
    # Need the scaler fitted on the *training* data
    scaler = StandardScaler().fit(X_train_original[feature_cols]) # Fit on original training features

    # Combine original train and test features
    X_full_original = pd.concat([X_train_original[feature_cols], X_test_original[feature_cols]])

    # Scale the full original data using the scaler fitted on training data
    X_full_scaled = scaler.transform(X_full_original)
    X_full_scaled_df = pd.DataFrame(X_full_scaled, columns=feature_cols, index=X_full_original.index)

    contrib_matrix_full = X_full_scaled_df.values * coefs
    contrib_df_full = pd.DataFrame(contrib_matrix_full, columns=feature_cols, index=X_full_scaled_df.index).fillna(0)
    contrib_df_full['BASELINE'] = intercept
    contrib_df_full['PREDICTION'] = contrib_df_full.sum(axis=1)

    # Bucket contributions (Need definitions of media_all, promo_vars, base_vars)
    # Let's try to infer buckets based on feature_cols or use a default if needed
    # This part might need manual adjustment or a more robust bucketing in Streamlit flow
    media_all = [c for c in feature_cols if any(k in c.lower() for k in ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']) and 'organic' not in c.lower()]
    promo_vars = [c for c in feature_cols if any(k in c.lower() for k in ['discount', 'promo', 'promotion', 'offer'])]
    base_vars = [c for c in feature_cols if c not in media_all + promo_vars]

    contrib_df_full['Media_contrib'] = contrib_df_full[[c for c in media_all if c in feature_cols]].sum(axis=1)
    contrib_df_full['Promo_contrib'] = contrib_df_full[[c for c in promo_vars if c in feature_cols]].sum(axis=1)
    contrib_df_full['Base_vars_contrib'] = contrib_df_full[[c for c in base_vars if c in feature_cols]].sum(axis=1)


    st.write("##### Contribution by Bucket Over Time")
    fig_bucket_contrib = go.Figure()
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Base_vars_contrib'], stackgroup='one', name='Base'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Media_contrib'], stackgroup='one', name='Media'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Promo_contrib'], stackgroup='one', name='Promo'))
    fig_bucket_contrib.update_layout(title="Contribution by Bucket",xaxis_title="Time",yaxis_title="Contribution")
    st.plotly_chart(fig_bucket_contrib)

    # Contributions by each variable (Media, Promo, Base) - example for Media
    st.write("##### Individual Variable Contributions Over Time")
    selected_bucket_for_plot = st.selectbox("Select bucket to plot individual contributions:", ["Media", "Promo", "Base"])

    if selected_bucket_for_plot == "Media":
        vars_to_plot = [c for c in media_all if c in feature_cols]
    elif selected_bucket_for_plot == "Promo":
        vars_to_plot = [c for c in promo_vars if c in feature_cols]
    else: # Base
        vars_to_plot = [c for c in base_vars if c in feature_cols]

    for var in vars_to_plot:
        if var + '_contrib' in contrib_df_full.columns:
            fig_var_contrib = go.Figure(go.Scatter(x=contrib_df_full.index, y=contrib_df_full[var+'_contrib'], mode='lines+markers', name=var))
            fig_var_contrib.update_layout(title=f"Contribution - {selected_bucket_for_plot}: {var}")
            st.plotly_chart(fig_var_contrib)


    # Feature importance (Coefficients)
    st.write("##### Feature Importance (Model Coefficients)")
    coef_df = pd.DataFrame({'feature': feature_cols, 'coef': coefs})
    coef_df['abscoef'] = coef_df['coef'].abs()
    coef_df = coef_df.sort_values('abscoef', ascending=False)
    fig_coef = px.bar(coef_df, x='feature', y='coef', title='Feature Coefficients', hover_data=['abscoef'])
    st.plotly_chart(fig_coef)

    # Response curves for each paid media (Need paid_media list and param_store)
    # Re-calculate paid_media and param_store based on feature_cols and df_features
    paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
    paid_media = [c for c in feature_cols if any(k in c.lower() for k in paid_keywords) and 'organic' not in c.lower()]

    # Re-calculate adstock/saturation parameters on the full original data
    param_store = {}
    ADSTOCK_DEFAULT_THETA = 0.4
    SAT_DEFAULT_BETA = 1e-6
    def adstock_geometric(x, theta):
        out = np.zeros_like(x, dtype=float)
        for t in range(len(x)):
            out[t] = x[t] + (theta*out[t-1] if t>0 else x[t])
        return out

    def sat_1mexp(x, beta):
        return 1.0 - np.exp(-beta * np.clip(x,0,None))

    def auto_theta(series):
        s = pd.Series(series).fillna(0.0)
        if len(s)<3 or s.std()==0: return ADSTOCK_DEFAULT_THETA
        ac1 = s.autocorr(lag=1)
        return float(np.clip(ac1 if not pd.isna(ac1) else ADSTOCK_DEFAULT_THETA, 0.0,0.9))

    def auto_beta(x_ad):
        med = np.median(x_ad[x_ad>0]) if np.any(x_ad>0) else 0.0
        return float(np.log(2.0)/(med+1e-12)) if med>0 else SAT_DEFAULT_BETA

    # Ensure df_features is available and has the columns needed for param_store
    if 'df_features' in st.session_state:
         df_features_for_params = st.session_state['df_features']
         for c in feature_cols:
             if c in df_features_for_params.columns: # Ensure column exists in original df
                 raw = df_features_for_params[c].fillna(0.0).astype(float).values
                 if c in paid_media:
                     theta = auto_theta(raw) # Use auto_theta for simplicity in Streamlit
                     x_ad = adstock_geometric(raw, theta)
                     beta = auto_beta(x_ad) # Use auto_beta
                     scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
                     param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
                 # No need to store params for non-paid media if not used in response curves

    st.write("##### Response Curves for Paid Media")
    MEP_PCT = 0.05
    OPT_PCT = 0.80
    DIM_THRESH_PCT = 0.01

    # Need the scaler fitted on the *training* data for prediction
    scaler = StandardScaler().fit(X_train_original[feature_cols])

    # Get median values for other variables from the scaled *training* data
    median_row_scaled_train = X_train_scaled.median().to_dict()

    for m in paid_media:
        if m in df_features.columns and m in param_store: # Ensure media var exists and params were stored
            maxv = max(1.0, df_features[m].max()) # Use original df_features for max value
            grid = np.linspace(0, maxv * 1.2, 120)
            preds = []

            theta = param_store[m]['theta']
            beta = param_store[m]['beta']
            scale = param_store[m]['scale']

            for g in grid:
                # Create a row with median scaled values for all features
                row_scaled = median_row_scaled_train.copy()

                # Transform the current grid value 'g' for variable 'm' with adstock/saturation
                # This requires applying adstock/saturation on a constant series 'g' and then scaling the result
                # A simpler approximation for response curves: just scale 'g' for the variable 'm'
                # and leave others at their median scaled training value. This is faster but an approximation.

                # Alternative: Apply adstock/saturation to a series of 'g' values, take the mean,
                # then scale that mean value. This aligns better with the model's training.
                temp_series = pd.Series(np.full(len(df_features), g)) # Use full length for consistent adstock context
                x_ad_g = adstock_geometric(temp_series.values, theta) if theta is not None else temp_series.values
                x_sat_g = sat_1mexp(x_ad_g, beta) if beta is not None else x_ad_g
                mean_transformed_g = np.mean(x_sat_g) * (scale if scale is not None else 1.0)

                # Need to scale this mean_transformed_g using the scaler's mean/std for *this specific variable m*
                # Find the scaler's mean and std for column 'm'
                try:
                    col_index = feature_cols.index(m)
                    scaled_mean_transformed_g = (mean_transformed_g - scaler.mean_[col_index]) / scaler.scale_[col_index]
                    row_scaled[m] = scaled_mean_transformed_g # Replace the scaled median with the scaled transformed grid value
                except Exception as scale_e:
                     st.warning(f"Could not scale transformed value for {m} at grid point {g:.2f}: {scale_e}")
                     row_scaled[m] = median_row_scaled_train[m] # Fallback to median if scaling fails


                X_row_scaled = pd.DataFrame([row_scaled], columns=feature_cols)

                try:
                    # Predict using the scaled row
                    yhat = model.predict(X_row_scaled)[0]
                    preds.append(yhat)
                except Exception as predict_e:
                    st.warning(f"Error predicting for {m} response curve at value {g:.2f}: {predict_e}")
                    preds.append(np.nan) # Append NaN on error

            preds = np.array(preds)
            preds = np.clip(preds, 0, None) # Clip predictions at 0
            # Remove NaNs if any occurred during prediction
            valid_preds_mask = ~np.isnan(preds)
            if not np.any(valid_preds_mask):
                 st.info(f"Skipping response curve for {m}: All predictions resulted in NaN.")
                 continue
            preds = preds[valid_preds_mask]
            grid_filtered = grid[valid_preds_mask]

            if len(preds) < 2:
                 st.info(f"Skipping response curve for {m}: Not enough valid prediction points.")
                 continue


            ymin, ymax = preds.min(), preds.max()
            eff = max(ymax - ymin, 1e-9)

            # Avoid errors if predictions are all the same (eff is tiny)
            if eff > 1e-9:
                mep_idx = np.argmax(preds >= (ymin + MEP_PCT * eff))
                opt_idx = np.argmax(preds >= (ymin + OPT_PCT * eff))
                dydx = np.gradient(preds, grid_filtered)
                init_slope = dydx[0] if len(dydx)>0 else 0 # Use the first slope

                if init_slope > 1e-9: # Check for positive initial slope
                    # Find index where slope drops below threshold
                    # Handle case where dydx might have NaNs or be non-positive
                    valid_slopes_idx = np.where(dydx > 1e-9)[0] # Only consider positive slopes
                    if valid_slopes_idx.size > 0:
                         # Find the first index where slope is <= threshold * initial_slope
                         dim_check = dydx[valid_slopes_idx] <= DIM_THRESH_PCT * init_slope
                         dim_indices = valid_slopes_idx[dim_check]
                         dim_idx = dim_indices[0] if dim_indices.size > 0 else len(grid_filtered) - 1
                    else:
                        dim_idx = len(grid_filtered) - 1 # If no positive slopes after the first, diminishing point is the end
                else:
                     dim_idx = len(grid_filtered) - 1 # If initial slope is zero or negative, diminishing point is the end


                fig = go.Figure(go.Scatter(x=grid_filtered, y=preds, mode='lines', name='Pred'))
                # Use grid_filtered indices for markers
                fig.add_trace(go.Scatter(x=[grid_filtered[mep_idx]], y=[preds[mep_idx]], mode='markers', marker=dict(color='blue', size=10), name='MEP'))
                fig.add_trace(go.Scatter(x=[grid_filtered[dim_idx]], y=[preds[dim_idx]], mode='markers', marker=dict(color='red', size=10), name='Diminishing'))
                # Use grid_filtered values for vrect
                fig.add_vrect(x0=grid_filtered[mep_idx], x1=grid_filtered[opt_idx], fillcolor="green", opacity=0.2, name='Optimal Range')
                fig.update_layout(title=f"Response Curve - {m}", xaxis_title=f"Transformed {m}", yaxis_title="Predicted Sales")
                st.plotly_chart(fig)
            else:
                 st.info(f"Skipping response curve for {m}: Predictions are constant or have no variation.")


    # Actual vs Predicted (AVP) chart
    st.write("##### Actual vs Predicted (AVP)")
    # Use the index from the full actual/predicted data for plotting
    plot_xaxis = df_features.index # Use original df_features index for dates

    fig_avp = go.Figure()
    fig_avp.add_trace(go.Scatter(x=plot_xaxis, y=y_full_actual, mode='lines+markers', name='Actual'))
    fig_avp.add_trace(go.Scatter(x=plot_full_xaxis, y=y_full_pred, mode='lines+markers', name='Predicted')) # Corrected x-axis

    # Find the date corresponding to the train/test split index
    train_n = len(y_train)
    if train_n < len(plot_xaxis):
         split_date = plot_xaxis[train_n] # Date of the first testing point
         fig_avp.add_vline(x=split_date, line=dict(color='red', dash='dash'), annotation_text='Train/Test Split')

    fig_avp.update_layout(title="Actual vs Predicted (AVP)", xaxis_title="Date", yaxis_title="Sales")
    st.plotly_chart(fig_avp)


# Wrap Scenario Analysis Module
def scenario_analysis_module():
    """
    Scenario analysis module, adapted for Streamlit
    """
    st.subheader("Scenario Analysis")

    # Retrieve model, data, and scaler from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_test_scaled = st.session_state.get('X_test_scaled')
    X_test_original = st.session_state.get('X_test_original') # Need original test data for scenario changes
    scaler = st.session_state.get('scaler') # Need the fitted scaler
    df_features = st.session_state.get('df_features') # Need df_features for transformations
    X_train_original = st.session_state.get('X_train_original') # Need original train data for transformations

    if model is None or feature_cols is None or X_test_scaled is None or X_test_original is None or scaler is None or df_features is None or X_train_original is None:
        st.info("Please train the model first to run scenario analysis.")
        return

    st.write("##### Create a Scenario")
    st.write("Modify the variables in the sidebar to see the predicted impact on sales.")

    scenario_changes = {}

    # Use sidebar for scenario inputs
    st.sidebar.subheader("Scenario Inputs (% Change)")
    st.sidebar.write("Enter percentage change (e.g., 20 for +20%, -10 for -10%).")

    # Dynamically create number inputs for each feature in the sidebar
    if feature_cols:
        for col in feature_cols:
            # Use a unique key for each widget
            change_pct = st.sidebar.number_input(f"{col}:", value=0.0, step=1.0, format="%.1f", key=f"scenario_{col}_change")
            scenario_changes[col] = change_pct / 100.0 # Store as proportion


    if st.button("Run Scenario"):
        st.write("Running scenario...")
        try:
            # Use the original test data as the base for the scenario
            # Apply the same transformations (adstock, saturation) to the test data
            # before scaling and predicting.

            # Re-calculate adstock/saturation parameters on the full original data (train+test)
            # to ensure consistency with model training.
            # Or, fit adstock/saturation on the training data and apply to test data.
            # Let's use the parameters derived from the full df_features as done in plotting
            # This requires access to the full df_features, which should be in session_state

            # Recalculate param_store using the full df_features from session state
            param_store = {}
            ADSTOCK_DEFAULT_THETA = 0.4
            SAT_DEFAULT_BETA = 1e-6
            paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
            paid_media = [c for c in feature_cols if any(k in c.lower() for k in paid_keywords) and 'organic' not in c.lower()]

            df_features_full = st.session_state['df_features'] # Full df with FE
            for c in feature_cols:
                 if c in df_features_full.columns:
                     raw = df_features_full[c].fillna(0.0).astype(float).values
                     if c in paid_media:
                         theta = auto_theta(raw)
                         x_ad = adstock_geometric(raw, theta)
                         beta = auto_beta(x_ad)
                         scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
                         param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
                     else:
                         param_store[c] = {"theta":None,"beta":None,"scale":1.0} # Store None for non-paid media

            # Apply transformations to the original test data based on param_store
            scenario_test_data_transformed = X_test_original.copy()
            for col in feature_cols:
                 if col in param_store:
                     raw_test = X_test_original[col].fillna(0.0).astype(float).values
                     theta = param_store[col]['theta']
                     beta = param_store[col]['beta']
                     scale = param_store[col]['scale']

                     # Apply adstock/saturation just to the test data section
                     # Need the historical context from training data for accurate adstock
                     # A proper implementation would require re-calculating adstock from the start
                     # up to the test period for the scenario.
                     # For simplicity here, we'll apply the transformation parameters to the test data in isolation,
                     # which is an approximation. A more complex approach needed for true adstock carryover.

                     # Simple approximation: apply transformation function to the test data series
                     # This is NOT ideal for adstock but ok for simple saturation/direct scaling
                     # A better way: Concatenate training data + test data (with scenario changes),
                     # apply adstock/saturation to the whole series, then slice the test part.

                     # Let's use the more accurate approach: concatenate train+test, apply transforms, slice test
                     X_train_original = st.session_state['X_train_original'][feature_cols] # Get train original features
                     full_original_data = pd.concat([X_train_original, X_test_original[feature_cols]])

                     # Apply scenario changes to the test portion of the full data
                     for var, change in scenario_changes.items():
                         if var in full_original_data.columns:
                              # Find the index of the test set start
                              test_start_idx = len(X_train_original)
                              full_original_data.loc[full_original_data.index[test_start_idx:], var] *= (1 + change)
                         else:
                              st.warning(f"Scenario variable '{var}' not found in full original data.")

                     # Apply transformations (adstock/saturation) to the *entire* series
                     full_transformed_data = pd.DataFrame(index=full_original_data.index)
                     for c in feature_cols:
                          if c in param_store and c in full_original_data.columns:
                              raw_full = full_original_data[c].fillna(0.0).astype(float).values
                              theta = param_store[c]['theta']
                              beta = param_store[c]['beta']
                              scale = param_store[c]['scale']

                              x_ad_full = adstock_geometric(raw_full, theta) if theta is not None else raw_full
                              x_sat_full = sat_1mexp(x_ad_full, beta) if beta is not None else x_ad_full
                              # Rescale using the scale factor derived from the full original data transformation step
                              # This assumes the scale factor was calculated based on the max of the full adstocked series
                              # Need to ensure param_store stores the correct scale (based on full data)
                              scaled_full = x_sat_full * (scale if scale is not None else 1.0)
                              full_transformed_data[c] = scaled_full
                          elif c in full_original_data.columns:
                               # Directly copy non-transformed columns
                               full_transformed_data[c] = full_original_data[c]
                          else:
                               st.warning(f"Column '{c}' not found in full original data during scenario transformation.")
                               full_transformed_data[c] = np.nan # Or handle missing column

                     # Slice the test portion after transformations
                     scenario_test_data_transformed = full_transformed_data.iloc[len(X_train_original):].copy()


            # Scale the scenario-transformed test data using the *same* scaler fitted on the training data
            try:
                # Align columns and fill NaNs before scaling
                scenario_test_data_aligned = scenario_test_data_transformed.reindex(columns=feature_cols, fill_value=0)
                if scenario_test_data_aligned.isnull().sum().sum() > 0:
                    st.warning("‚ö†Ô∏è  NaN values detected in scenario data before scaling. Filling with 0.")
                    scenario_test_data_aligned = scenario_test_data_aligned.fillna(0)

                scenario_data_scaled = scaler.transform(scenario_test_data_aligned)
                st.write("‚úÖ Scenario data scaled.")
            except Exception as e:
                st.error(f"‚ùå Error during scaling scenario data: {e}")
                return None


            # Predict new outcome
            try:
                if np.isnan(scenario_data_scaled).sum() > 0:
                     st.error("‚ùå NaN values detected in scaled scenario data before prediction.")
                     return None

                y_pred_scenario = model.predict(scenario_data_scaled)
                y_pred_scenario = np.clip(y_pred_scenario, 0, None)
                st.write("‚úÖ Scenario predictions generated (clipped at 0).")
            except Exception as e:
                 st.error(f"‚ùå Error during scenario prediction: {e}")
                 return None


            # Get baseline prediction on the test set (X_test_scaled is available in session state)
            y_base = model.predict(X_test_scaled)
            y_base = np.clip(y_base, 0, None)
            st.write("‚úÖ Baseline predictions generated (clipped at 0).")


            # Create a results DataFrame - Use the index from the original test set
            results_df = pd.DataFrame({
                'Baseline_Prediction': y_base,
                'Scenario_Prediction': y_pred_scenario
            }, index=X_test_original.index)


            # Calculate Lift (percentage change from baseline)
            results_df['Sales_Lift_Pct'] = np.nan
            valid_baseline_mask = (results_df['Baseline_Prediction'] != 0) & (~results_df['Baseline_Prediction'].isna())

            results_df.loc[valid_baseline_mask, 'Sales_Lift_Pct'] = (
                (results_df.loc[valid_baseline_mask, 'Scenario_Prediction'] - results_df.loc[valid_baseline_mask, 'Baseline_Prediction']) /
                results_df.loc[valid_baseline_mask, 'Baseline_Prediction'] * 100
            )

            st.write("\nüìä Scenario Analysis Results:")
            st.write("="*40)
            st.write(f"Total Baseline Sales: ‚Çπ{results_df['Baseline_Prediction'].sum():,.0f}")
            st.write(f"Total Scenario Sales: ‚Çπ{results_df['Scenario_Prediction'].sum():,.0f}")
            st.write(f"Total Sales Lift: ‚Çπ{(results_df['Scenario_Prediction'].sum() - results_df['Baseline_Prediction'].sum()):,.0f}")
            st.write(f"Average Weekly Sales Lift Percentage: {results_df['Sales_Lift_Pct'].mean():.2f}%")


            st.write("üìã SCENARIO RESULTS DATAFRAME (first 5 rows):")
            st.dataframe(results_df.head())

            # Plot baseline vs scenario predictions
            plot_xaxis = results_df.index # Use the index of the results_df (which is the date index) for the x-axis
            fig_scenario = go.Figure()
            fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=results_df['Baseline_Prediction'], mode='lines+markers', name='Baseline Prediction'))
            fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=results_df['Scenario_Prediction'], mode='lines+markers', name='Scenario Prediction'))
            fig_scenario.update_layout(title="Baseline vs Scenario Predictions",
                                      xaxis_title="Date",
                                      yaxis_title="Predicted Sales")
            st.plotly_chart(fig_scenario)

        except Exception as e:
            st.error(f"‚ùå An error occurred during scenario execution: {str(e)}")


# --- Main Streamlit App Flow ---
def main():
    """
    Main function to run the Streamlit MMM application.
    """
    st.sidebar.header("File Upload")
    uploaded_file = st.sidebar.file_uploader("Upload your CSV file", type=["csv"])

    df = None
    if uploaded_file is not None:
        # Load and preprocess data
        df = load_and_preprocess_data(uploaded_file)
        st.session_state['original_data'] = df.copy() # Store original data

        st.subheader("Raw Data Preview")
        st.write(f"Shape: {df.shape}")
        st.dataframe(df.head())

        # Perform EDA (Optional - can be added as a separate section if needed)
        # st.subheader("Exploratory Data Analysis (EDA)")
        # Note: Comprehensive EDA plots might be too many for a basic Streamlit app.
        # Consider adding key EDA plots selectively or on demand.

        # Check if data loading was successful and has required columns
        if df is not None and 'Sales' in df.columns and 'Week_Ending' in df.columns:

            # Feature Engineering
            st.write("---") # Separator
            df_features = feature_engineering_module(df.copy())
            st.session_state['df_features'] = df_features.copy() # Store df with features

            # Define feature columns for modeling (exclude date and target)
            feature_cols = [col for col in df_features.columns if col not in ['Week_Ending', 'Sales'] and col is not None]

            if feature_cols:
                 # Model Preprocessing
                 st.write("---") # Separator
                 X_train_scaled, X_test_scaled, y_train, y_test, scaler = model_preprocessing(
                     df_features,
                     feature_cols,
                     target_column='Sales'
                 )

                 # Store preprocessing results in session state
                 st.session_state['feature_cols'] = feature_cols
                 st.session_state['X_train_scaled'] = X_train_scaled
                 st.session_state['X_test_scaled'] = X_test_scaled
                 st.session_state['y_train'] = y_train
                 st.session_state['y_test'] = y_test
                 st.session_state['scaler'] = scaler
                 # Store original train/test splits for scenario analysis base
                 # Ensure these are based on df_features, not the raw df
                 st.session_state['X_train_original'] = df_features[feature_cols].iloc[:len(y_train)].copy()
                 st.session_state['X_test_original'] = df_features[feature_cols].iloc[len(y_train):].copy()


                 # Model Selection and Training
                 st.write("---") # Separator
                 model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols)

                 # Model Evaluation and Plotting (only run if model is trained)
                 if st.session_state.get('trained_model') is not None:
                      st.write("---") # Separator
                      model_evaluation_and_plotting()

                 # Scenario Analysis (only run if model is trained and original data splits are available)
                 if st.session_state.get('trained_model') is not None and st.session_state.get('X_test_original') is not None:
                      st.write("---") # Separator
                      scenario_analysis_module()
                 elif st.session_state.get('trained_model') is not None:
                      st.warning("Scenario Analysis skipped: Original train/test data splits are missing.")


            else:
                 st.warning("No features available for modeling after preprocessing.")
        else:
            if uploaded_file is not None:
                 st.error("Uploaded file does not contain 'Sales' or 'Week_Ending' columns, or data loading failed.")

    else:
        st.info("Please upload a CSV file to get started.")

# Run the main function
if __name__ == "__main__":
    main()

import streamlit as st
import pandas as pd
import numpy as np
import warnings
from datetime import datetime
from statsmodels.tsa.seasonal import seasonal_decompose
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Ridge, Lasso, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
from statsmodels.stats.outliers_influence import variance_inflation_factor
from statsmodels.stats.stattools import durbin_watson
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import math
import difflib # Still might be useful for fuzzy matching in interactive mode

# Remove Colab-specific commands and display functions
# %store data # Removed
# %store numeric_df # Removed
# %store correlations # Removed
# %store df_features # Removed
# display() # Will be replaced by st.write/st.dataframe/st.plotly_chart

# Remove Colab-specific import for display
# from IPython.display import display # Removed


warnings.filterwarnings('ignore')

st.title("Marketing Mix Modeling (MMM) Streamlit App")

# Set up a sidebar for potential controls later
st.sidebar.title("App Controls")

# Function to convert Indian number format to float
def convert_indian_number(value):
    """Convert Indian number format string to float"""
    if isinstance(value, str):
        cleaned_value = value.replace(',', '').strip()
        if cleaned_value in ['-', ''] or cleaned_value.isspace():
            return np.nan
        try:
            return float(cleaned_value)
        except ValueError:
            # st.warning(f"Could not convert value: '{value}'") # Use st.warning for Streamlit
            return np.nan
    return value

# Wrap data loading and preprocessing
@st.cache_data
def load_and_preprocess_data(uploaded_file):
    """Load and preprocess the marketing mix data from an uploaded file object"""
    # st.write("Loading and preprocessing data...") # Use st.write for Streamlit

    # Load the data directly from the uploaded file object
    data = pd.read_csv(uploaded_file)

    all_columns = data.columns.tolist()
    date_column = 'Week_Ending'

    if date_column in all_columns:
        all_columns.remove(date_column)

    for col in all_columns:
        if data[col].dtype == 'object' and data[col].str.contains(',').any():
            data[col] = data[col].apply(convert_indian_number)
        elif data[col].dtype == 'object':
             data[col] = data[col].apply(convert_indian_number)

    if 'Paid Search Impressions' in data.columns:
        missing_count = data['Paid Search Impressions'].isna().sum()
        if missing_count > 0:
            st.warning(f"Found {missing_count} missing values in 'Paid Search Impressions'. Imputing with 0.")
            data['Paid Search Impressions'] = data['Paid Search Impressions'].fillna(0)

    if 'Week_Ending' in data.columns:
        data['Week_Ending'] = pd.to_datetime(data['Week_Ending'], format='%d-%m-%Y %H:%M', errors='coerce')
        data = data.sort_values('Week_Ending').reset_index(drop=True)

    # st.write("Data loading and preprocessing complete.") # Use st.write for Streamlit
    return data

# Wrap Feature Engineering
def feature_engineering_module(df):
    """
    Feature engineering module for time series data, adapted for Streamlit
    """
    st.subheader("Feature Engineering")
    df = df.copy()
    original_columns = set(df.columns)

    if 'Week_Ending' in df.columns:
        df['Week_Ending'] = pd.to_datetime(df['Week_Ending'])
        df = df.set_index('Week_Ending').sort_index()
    else:
         st.error("DataFrame must contain a 'Week_Ending' column for feature engineering.")
         return df # Return original df or handle error

    # 1. Seasonal Index (SIndex) - Using Streamlit selectbox
    st.write("##### 1. Seasonal Index")
    period_options = {
        "4 weeks (monthly pattern)": 4,
        "13 weeks (quarterly pattern)": 13,
        "26 weeks (half-yearly pattern)": 26,
        "52 weeks (yearly pattern)": 52
    }
    selected_period_label = st.selectbox(
        "Select seasonality period:",
        list(period_options.keys()),
        index=3 # Default to 52 weeks
    )
    period = period_options[selected_period_label]

    if len(df) >= 2 * period:
        try:
            decomp = seasonal_decompose(df['Sales'], period=period, model='additive', extrapolate_trend='freq')
            df['SIndex'] = decomp.seasonal
            st.success(f"‚úÖ Seasonal Index created with period={period}")
        except Exception as e:
            st.warning(f"‚ö†Ô∏è Could not create Seasonal Index with period {period}: {str(e)}")
    else:
        st.warning(f"‚ö†Ô∏è Not enough data points ({len(df)}) for seasonality period {period}. Skipping Seasonal Index.")


    # 2. Holiday Dummies - Using Streamlit checkbox and text input
    st.write("##### 2. Holiday Dummies")
    add_dummies = st.checkbox("Add holiday dummies?")
    if add_dummies:
        holiday_dates_str = st.text_input("Enter holiday dates (comma separated, format YYYY-MM-DD):")
        if holiday_dates_str.strip():
            dates = [d.strip() for d in holiday_dates_str.split(",") if d.strip()]
            for i, d in enumerate(dates, start=1):
                try:
                    holiday_date = pd.to_datetime(d)
                    col_name = f"Holiday_{i}"
                    df[col_name] = (df.index == holiday_date).astype(int)
                    st.success(f"‚úÖ Added dummy: {col_name} for {d}")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Could not parse date: {d}. Error: {str(e)}")
        else:
            st.info("Enter dates to add holiday dummies.")


    # 3. Split Variable - Using Streamlit checkbox, selectbox and date input
    st.write("##### 3. Split Variable")
    split_choice = st.checkbox("Split a variable at a date?")
    if split_choice:
        all_vars_for_split = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_split:
            var_to_split = st.selectbox("Select variable to split:", all_vars_for_split)
            split_date = st.date_input("Enter split date:")

            if var_to_split and split_date:
                try:
                    split_dt = pd.to_datetime(split_date)
                    df[f"{var_to_split}_pre"] = np.where(df.index <= split_dt, df[var_to_split], 0)
                    df[f"{var_to_split}_post"] = np.where(df.index > split_dt, df[var_to_split], 0)
                    df.drop(columns=[var_to_split], inplace=True)
                    st.success(f"‚úÖ Split '{var_to_split}' into '{var_to_split}_pre' and '{var_to_split}_post' at {split_dt.date()}")
                    st.info(f"Original variable '{var_to_split}' dropped.")
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Error splitting variable: {str(e)}")
        else:
             st.info("No suitable variables available for splitting.")


    # 4. Super Campaign - Using Streamlit checkbox and multiselect
    st.write("##### 4. Super Campaign")
    super_choice = st.checkbox("Create a super campaign?")
    if super_choice:
        all_vars_for_combine = [col for col in df.columns if col not in ['SIndex', 'Sales'] and not col.endswith(('_pre', '_post'))]
        if all_vars_for_combine:
            vars_to_combine = st.multiselect("Select variables to combine:", all_vars_for_combine)

            if vars_to_combine:
                custom_name_choice = st.checkbox("Provide a custom name for the super campaign?")
                if custom_name_choice:
                    super_col = st.text_input("Enter the custom name:")
                    if not super_col:
                         st.warning("Custom name cannot be empty. Using default name 'combined_var'.")
                         super_col = "combined_var"
                else:
                    super_col = "combined_var"

                if super_col in df.columns:
                     st.warning(f"Column '{super_col}' already exists. Please choose a different name or uncheck 'Provide a custom name'.")
                else:
                    try:
                        df[super_col] = df[vars_to_combine].sum(axis=1)
                        st.success(f"‚úÖ Created Super Campaign: '{super_col}' combining {vars_to_combine}")
                        df.drop(columns=vars_to_combine, inplace=True)
                        st.info(f"Original variables {vars_to_combine} dropped.")

                        # Display verification of sums
                        st.write(f"Verification of sums for '{super_col}':")
                        verification_data = []
                        for var in vars_to_combine:
                            verification_data.append({"Variable": var, "Total Sum": df[var].sum()})
                        verification_data.append({"Variable": super_col, "Total Sum": df[super_col].sum()})
                        st.dataframe(pd.DataFrame(verification_data))

                    except Exception as e:
                        st.warning(f"‚ö†Ô∏è Error creating Super Campaign: {str(e)}")
            else:
                st.info("Select variables to combine for the super campaign.")
        else:
            st.info("No suitable variables available for combining into a super campaign.")


    # Show extra features created
    new_features = sorted(set(df.columns) - original_columns)
    if new_features:
        st.subheader("üìä Extra Features Created:")
        feature_info = []
        for col in new_features:
            feature_type = "Seasonal Index" if col == "SIndex" else \
                           "Holiday Dummy" if col.startswith("Holiday_") else \
                           "Split Variable" if col.endswith(('_pre', '_post')) else \
                           "Super Campaign" if col in ['combined_var', 'Super_Campaign'] else "Other"
            feature_info.append({
                "Feature Name": col,
                "Type": feature_type,
                "Data Type": str(df[col].dtype),
                "Non-Zero Values": f"{(df[col] != 0).sum()} / {len(df)}"
            })
        st.dataframe(pd.DataFrame(feature_info))
        st.write("Sample of new features:")
        st.dataframe(df[new_features].head())
    else:
        st.info("‚ÑπÔ∏è No additional features were created.")

    return df

# Wrap Model Preprocessing
def model_preprocessing(df, feature_columns, target_column='Sales', test_size=0.2):
    """
    Preprocess data for modeling: scaling and time-based train-test split, adapted for Streamlit
    """
    st.subheader("Model Preprocessing")

    if feature_columns is None or not feature_columns:
        st.warning("No features selected for modeling.")
        return None, None, None, None, None

    X = df[feature_columns].copy()
    y = df[target_column].copy()

    st.write(f"Original feature shapes: X={X.shape}, y={y.shape}")

    # Time-based train-test split (Streamlit number input)
    st.write("##### Train-Test Split")
    test_size = st.slider("Select test set size (proportion):", min_value=0.1, max_value=0.5, value=test_size, step=0.05)
    split_idx = int(len(X) * (1 - test_size))

    X_train = X.iloc[:split_idx].copy()
    X_test = X.iloc[split_idx:].copy()
    y_train = y.iloc[:split_idx].copy()
    y_test = y.iloc[split_idx:].copy()

    st.write(f"After time-based split:")
    st.write(f"X_train: {X_train.shape}, X_test: {X_test.shape}")
    st.write(f"y_train: {y_train.shape}, y_test: {y_test.shape}")

    # Scale the features
    st.write("##### Feature Scaling")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)

    X_train_scaled = pd.DataFrame(X_train_scaled, columns=feature_columns, index=X_train.index)
    X_test_scaled = pd.DataFrame(X_test_scaled, columns=feature_columns, index=X_test.index)

    st.success("‚úÖ Features scaled using StandardScaler")
    st.success("‚úÖ Time-based train-test split completed")

    st.write("Preview of scaled training data (first 5 rows):")
    st.dataframe(X_train_scaled.head())
    st.write("Preview of target variable (first 5 rows):")
    st.dataframe(y_train.head())

    return X_train_scaled, X_test_scaled, y_train, y_test, scaler

# Wrap Model Selection and Training
def model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols):
    """
    Interactive model selection and training, adapted for Streamlit
    """
    st.subheader("Model Selection and Training")

    if X_train_scaled is None or y_train is None:
        st.warning("Missing training data. Please complete previous steps.")
        return None, None, None

    # Model Selection (Streamlit selectbox)
    model_options = {
        "ElasticNet": ElasticNet,
        "Ridge": Ridge,
        "Lasso": Lasso
    }
    selected_model_name = st.selectbox("Select Model:", list(model_options.keys()), index=0)
    model_class = model_options[selected_model_name]

    # Simple Hyperparameter Input (Streamlit number_input)
    st.write("##### Hyperparameters (simple input)")
    alpha = st.number_input("Alpha:", min_value=0.0001, value=0.01, step=0.001, format="%.4f")
    l1_ratio = None
    if selected_model_name == "ElasticNet":
        l1_ratio = st.slider("L1 Ratio (for ElasticNet):", min_value=0.0, max_value=1.0, value=0.5, step=0.05)

    # Model reasons/notes (Streamlit text area)
    st.write("##### Model Rationale")
    reasons = st.multiselect(
        "Why this model?",
        [
            "High multicollinearity",
            "Need feature selection",
            "Balance selection & stability",
            "Small dataset",
            "Interpretability matters",
            "Sparse true drivers expected",
            "Reduce overfitting risk",
        ],
        default=["Balance selection & stability"] if selected_model_name == "ElasticNet" else []
    )
    notes = st.text_area("Additional Notes/Hypothesis:")

    # Training Button
    if st.button("Train Model"):
        st.write("Training model...")
        try:
            # Instantiate model with selected hyperparameters
            if selected_model_name == "ElasticNet":
                model = model_class(alpha=alpha, l1_ratio=l1_ratio, max_iter=20000)
            elif selected_model_name == "Lasso":
                 model = model_class(alpha=alpha, max_iter=20000)
            else: # Ridge
                 model = model_class(alpha=alpha)

            model.fit(X_train_scaled, y_train)
            st.success(f"‚úÖ Model '{selected_model_name}' trained successfully!")

            # Store model and other relevant info in session state
            st.session_state['trained_model'] = model
            st.session_state['feature_cols'] = feature_cols
            st.session_state['X_train_scaled'] = X_train_scaled
            st.session_state['X_test_scaled'] = X_test_scaled
            st.session_state['y_train'] = y_train
            st.session_state['y_test'] = y_test
            # Store original train/test splits for scenario analysis base (if not already stored)
            if 'X_train_original' not in st.session_state or 'X_test_original' not in st.session_state:
                 st.warning("Original train/test data not found in session state. Scenario analysis might be limited.")
                 # Attempt to reconstruct if possible, or skip scenario analysis later
                 if 'df_features' in st.session_state and 'y_train' in st.session_state:
                      train_n = len(st.session_state['y_train'])
                      all_features = [col for col in st.session_state['df_features'].columns if col not in ['Week_Ending', 'Sales']]
                      st.session_state['X_train_original'] = st.session_state['df_features'][all_features].iloc[:train_n].copy()
                      st.session_state['X_test_original'] = st.session_state['df_features'][all_features].iloc[len(y_train):].copy() # Corrected slicing
                      st.info("Attempted to reconstruct original train/test data from df_features.")
                 else:
                      st.error("Cannot reconstruct original train/test data. Scenario analysis will not be available.")
                      st.session_state['X_train_original'] = None
                      st.session_state['X_test_original'] = None


            # Display basic performance metrics after training
            y_train_pred = model.predict(X_train_scaled)
            y_test_pred = model.predict(X_test_scaled)
            train_r2 = r2_score(y_train, y_train_pred)
            test_r2 = r2_score(y_test, y_test_pred)
            train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
            test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))

            st.write("##### Training Performance")
            st.write(f"Train R¬≤: {train_r2:.3f}")
            st.write(f"Train RMSE: {train_rmse:,.0f}")
            st.write("##### Test Performance")
            st.write(f"Test R¬≤: {test_r2:.3f}")
            st.write(f"Test RMSE: {test_rmse:,.0f}")


        except Exception as e:
            st.error(f"‚ùå Error during model training: {str(e)}")
            st.session_state['trained_model'] = None # Ensure model is None on failure

    # Return None immediately, the model will be accessed via st.session_state
    return None, None, None # Returning model, coefficients, intercept might be confusing with session state

# Wrap Model Evaluation and Plotting
def model_evaluation_and_plotting():
    """
    Evaluate and plot model results, adapted for Streamlit
    """
    st.subheader("Model Evaluation and Results")

    # Retrieve model and data from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_train_scaled = st.session_state.get('X_train_scaled')
    X_test_scaled = st.session_state.get('X_test_scaled')
    y_train = st.session_state.get('y_train')
    y_test = st.session_state.get('y_test')
    df_features = st.session_state.get('df_features') # Need original df for indexing/dates
    X_train_original = st.session_state.get('X_train_original') # Need original train data for scaling
    X_test_original = st.session_state.get('X_test_original') # Need original test data for scaling

    # Check if necessary data is available in session state
    if model is None or feature_cols is None or X_train_scaled is None or X_test_scaled is None or y_train is None or y_test is None or df_features is None or X_train_original is None or X_test_original is None:
        st.info("Please train the model first.")
        return

    st.write("##### Model Performance Metrics")

    y_train_pred = model.predict(X_train_scaled)
    y_test_pred = model.predict(X_test_scaled)
    y_full_pred = np.concatenate([y_train_pred, y_test_pred])
    y_full_actual = np.concatenate([y_train, y_test]) # Need full actual for some metrics

    # Calculate metrics
    def mape(a,b):
        a,b = np.array(a),np.array(b); mask = a!=0
        return np.mean(np.abs((a[mask]-b[mask])/a[mask]))*100 if mask.any() else np.nan

    train_r2 = r2_score(y_train, y_train_pred)
    test_r2 = r2_score(y_test, y_test_pred)
    train_rmse = np.sqrt(mean_squared_error(y_train, y_train_pred))
    test_rmse = np.sqrt(mean_squared_error(y_test, y_test_pred))
    train_mape = mape(y_train, y_train_pred)
    test_mape = mape(y_test, y_test_pred)

    # Durbin-Watson for residuals on the full dataset for time series
    resid_full = y_full_actual - y_full_pred
    try:
         dw_stat = durbin_watson(resid_full)
    except:
         dw_stat = np.nan # Handle potential errors if residuals are constant etc.


    metrics_data = {
        "Metric": ["R2 (%)", "RMSE", "MAPE (%)", "Durbin-Watson (Full Residuals)"],
        "Train": [train_r2*100, train_rmse, train_mape, np.nan], # DW is for full data
        "Test": [test_r2*100, test_rmse, test_mape, np.nan] # DW is for full data
    }
    metrics_df = pd.DataFrame(metrics_data)

    # Add DW stat separately or to a combined row
    metrics_df.loc[metrics_df['Metric'] == "Durbin-Watson (Full Residuals)", ['Train', 'Test']] = dw_stat # Display in both columns or adjust table structure

    st.dataframe(metrics_df.set_index('Metric'))

    # Fit Warning
    fit_warning = ""
    if (train_r2*100 - test_r2*100) > 10:
        fit_warning="Possible Overfitting"
    elif test_r2*100 < 50:
        fit_warning="Underfitting"
    if fit_warning:
        st.warning(f"Fit Warning: {fit_warning}")

    # Contributions Calculation (re-calculate as it wasn't stored globally)
    coefs = model.coef_
    intercept = model.intercept_
    # Calculate on training set for average contribution interpretation
    contrib_matrix = X_train_scaled.values * coefs
    contrib_df_train = pd.DataFrame(contrib_matrix, columns=feature_cols, index=X_train_scaled.index).fillna(0)
    contrib_df_train['BASELINE'] = intercept

    # Calculate average contributions
    avg_contrib = contrib_df_train.mean().sort_values(ascending=False)
    st.write("##### Average Feature Contributions (on Training Data)")
    st.dataframe(avg_contrib.to_frame("Average Contribution"))

    # Contributions over Time (using full scaled data X_full_s if available)
    # Need the scaler fitted on the *training* data
    scaler = StandardScaler().fit(X_train_original[feature_cols]) # Fit on original training features

    # Combine original train and test features
    X_full_original = pd.concat([X_train_original[feature_cols], X_test_original[feature_cols]])

    # Scale the full original data using the scaler fitted on training data
    X_full_scaled = scaler.transform(X_full_original)
    X_full_scaled_df = pd.DataFrame(X_full_scaled, columns=feature_cols, index=X_full_original.index)

    contrib_matrix_full = X_full_scaled_df.values * coefs
    contrib_df_full = pd.DataFrame(contrib_matrix_full, columns=feature_cols, index=X_full_scaled_df.index).fillna(0)
    contrib_df_full['BASELINE'] = intercept
    contrib_df_full['PREDICTION'] = contrib_df_full.sum(axis=1)

    # Bucket contributions (Need definitions of media_all, promo_vars, base_vars)
    # Let's try to infer buckets based on feature_cols or use a default if needed
    # This part might need manual adjustment or a more robust bucketing in Streamlit flow
    media_all = [c for c in feature_cols if any(k in c.lower() for k in ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']) and 'organic' not in c.lower()]
    promo_vars = [c for c in feature_cols if any(k in c.lower() for k in ['discount', 'promo', 'promotion', 'offer'])]
    base_vars = [c for c in feature_cols if c not in media_all + promo_vars]

    contrib_df_full['Media_contrib'] = contrib_df_full[[c for c in media_all if c in feature_cols]].sum(axis=1)
    contrib_df_full['Promo_contrib'] = contrib_df_full[[c for c in promo_vars if c in feature_cols]].sum(axis=1)
    contrib_df_full['Base_vars_contrib'] = contrib_df_full[[c for c in base_vars if c in feature_cols]].sum(axis=1)


    st.write("##### Contribution by Bucket Over Time")
    fig_bucket_contrib = go.Figure()
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Base_vars_contrib'], stackgroup='one', name='Base'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Media_contrib'], stackgroup='one', name='Media'))
    fig_bucket_contrib.add_trace(go.Scatter(x=contrib_df_full.index, y=contrib_df_full['Promo_contrib'], stackgroup='one', name='Promo'))
    fig_bucket_contrib.update_layout(title="Contribution by Bucket",xaxis_title="Time",yaxis_title="Contribution")
    st.plotly_chart(fig_bucket_contrib)

    # Contributions by each variable (Media, Promo, Base) - example for Media
    st.write("##### Individual Variable Contributions Over Time")
    selected_bucket_for_plot = st.selectbox("Select bucket to plot individual contributions:", ["Media", "Promo", "Base"])

    if selected_bucket_for_plot == "Media":
        vars_to_plot = [c for c in media_all if c in feature_cols]
    elif selected_bucket_for_plot == "Promo":
        vars_to_plot = [c for c in promo_vars if c in feature_cols]
    else: # Base
        vars_to_plot = [c for c in base_vars if c in feature_cols]

    for var in vars_to_plot:
        if var + '_contrib' in contrib_df_full.columns:
            fig_var_contrib = go.Figure(go.Scatter(x=contrib_df_full.index, y=contrib_df_full[var+'_contrib'], mode='lines+markers', name=var))
            fig_var_contrib.update_layout(title=f"Contribution - {selected_bucket_for_plot}: {var}")
            st.plotly_chart(fig_var_contrib)


    # Feature importance (Coefficients)
    st.write("##### Feature Importance (Model Coefficients)")
    coef_df = pd.DataFrame({'feature': feature_cols, 'coef': coefs})
    coef_df['abscoef'] = coef_df['coef'].abs()
    coef_df = coef_df.sort_values('abscoef', ascending=False)
    fig_coef = px.bar(coef_df, x='feature', y='coef', title='Feature Coefficients', hover_data=['abscoef'])
    st.plotly_chart(fig_coef)

    # Response curves for each paid media (Need paid_media list and param_store)
    # Re-calculate paid_media and param_store based on feature_cols and df_features
    paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
    paid_media = [c for c in feature_cols if any(k in c.lower() for k in paid_keywords) and 'organic' not in c.lower()]

    # Re-calculate adstock/saturation parameters on the full original data
    param_store = {}
    ADSTOCK_DEFAULT_THETA = 0.4
    SAT_DEFAULT_BETA = 1e-6
    def adstock_geometric(x, theta):
        out = np.zeros_like(x, dtype=float)
        for t in range(len(x)):
            out[t] = x[t] + (theta*out[t-1] if t>0 else x[t])
        return out

    def sat_1mexp(x, beta):
        return 1.0 - np.exp(-beta * np.clip(x,0,None))

    def auto_theta(series):
        s = pd.Series(series).fillna(0.0)
        if len(s)<3 or s.std()==0: return ADSTOCK_DEFAULT_THETA
        ac1 = s.autocorr(lag=1)
        return float(np.clip(ac1 if not pd.isna(ac1) else ADSTOCK_DEFAULT_THETA, 0.0,0.9))

    def auto_beta(x_ad):
        med = np.median(x_ad[x_ad>0]) if np.any(x_ad>0) else 0.0
        return float(np.log(2.0)/(med+1e-12)) if med>0 else SAT_DEFAULT_BETA

    # Ensure df_features is available and has the columns needed for param_store
    if 'df_features' in st.session_state:
         df_features_for_params = st.session_state['df_features']
         for c in feature_cols:
             if c in df_features_for_params.columns: # Ensure column exists in original df
                 raw = df_features_for_params[c].fillna(0.0).astype(float).values
                 if c in paid_media:
                     theta = auto_theta(raw) # Use auto_theta for simplicity in Streamlit
                     x_ad = adstock_geometric(raw, theta)
                     beta = auto_beta(x_ad) # Use auto_beta
                     scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
                     param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
                 # No need to store params for non-paid media if not used in response curves

    st.write("##### Response Curves for Paid Media")
    MEP_PCT = 0.05
    OPT_PCT = 0.80
    DIM_THRESH_PCT = 0.01

    # Need the scaler fitted on the *training* data for prediction
    scaler = StandardScaler().fit(X_train_original[feature_cols])

    # Get median values for other variables from the scaled *training* data
    median_row_scaled_train = X_train_scaled.median().to_dict()

    for m in paid_media:
        if m in df_features.columns and m in param_store: # Ensure media var exists and params were stored
            maxv = max(1.0, df_features[m].max()) # Use original df_features for max value
            grid = np.linspace(0, maxv * 1.2, 120)
            preds = []

            theta = param_store[m]['theta']
            beta = param_store[m]['beta']
            scale = param_store[m]['scale']

            for g in grid:
                # Create a row with median scaled values for all features
                row_scaled = median_row_scaled_train.copy()

                # Transform the current grid value 'g' for variable 'm' with adstock/saturation
                # This requires applying adstock/saturation on a constant series 'g' and then scaling the result
                # A simpler approximation for response curves: just scale 'g' for the variable 'm'
                # and leave others at their median scaled training value. This is faster but an approximation.

                # Alternative: Apply adstock/saturation to a series of 'g' values, take the mean,
                # then scale that mean value. This aligns better with the model's training.
                temp_series = pd.Series(np.full(len(df_features), g)) # Use full length for consistent adstock context
                x_ad_g = adstock_geometric(temp_series.values, theta) if theta is not None else temp_series.values
                x_sat_g = sat_1mexp(x_ad_g, beta) if beta is not None else x_ad_g
                mean_transformed_g = np.mean(x_sat_g) * (scale if scale is not None else 1.0)

                # Need to scale this mean_transformed_g using the scaler's mean/std for *this specific variable m*
                # Find the scaler's mean and std for column 'm'
                try:
                    col_index = feature_cols.index(m)
                    # Handle potential division by zero if scaler.scale_[col_index] is 0 or very close
                    if scaler.scale_[col_index] != 0:
                        scaled_mean_transformed_g = (mean_transformed_g - scaler.mean_[col_index]) / scaler.scale_[col_index]
                    else:
                        scaled_mean_transformed_g = 0.0 # Or handle as appropriate if std dev is 0
                    row_scaled[m] = scaled_mean_transformed_g # Replace the scaled median with the scaled transformed grid value
                except Exception as scale_e:
                     st.warning(f"Could not scale transformed value for {m} at grid point {g:.2f}: {scale_e}")
                     row_scaled[m] = median_row_scaled_train[m] # Fallback to median if scaling fails


                X_row_scaled = pd.DataFrame([row_scaled], columns=feature_cols)

                try:
                    # Predict using the scaled row
                    yhat = model.predict(X_row_scaled)[0]
                    preds.append(yhat)
                except Exception as predict_e:
                    st.warning(f"Error predicting for {m} response curve at value {g:.2f}: {predict_e}")
                    preds.append(np.nan) # Append NaN on error

            preds = np.array(preds)
            preds = np.clip(preds, 0, None) # Clip predictions at 0
            # Remove NaNs if any occurred during prediction
            valid_preds_mask = ~np.isnan(preds)
            if not np.any(valid_preds_mask):
                 st.info(f"Skipping response curve for {m}: All predictions resulted in NaN.")
                 continue
            preds = preds[valid_preds_mask]
            grid_filtered = grid[valid_preds_mask]

            if len(preds) < 2:
                 st.info(f"Skipping response curve for {m}: Not enough valid prediction points.")
                 continue


            ymin, ymax = preds.min(), preds.max()
            eff = max(ymax - ymin, 1e-9)

            # Avoid errors if predictions are all the same (eff is tiny)
            if eff > 1e-9:
                mep_idx = np.argmax(preds >= (ymin + MEP_PCT * eff))
                opt_idx = np.argmax(preds >= (ymin + OPT_PCT * eff))
                dydx = np.gradient(preds, grid_filtered)
                init_slope = dydx[0] if len(dydx)>0 else 0 # Use the first slope

                if init_slope > 1e-9: # Check for positive initial slope
                    # Find index where slope drops below threshold
                    # Handle case where dydx might have NaNs or be non-positive
                    valid_slopes_idx = np.where(dydx > 1e-9)[0] # Only consider positive slopes
                    if valid_slopes_idx.size > 0:
                         # Find the first index where slope is <= threshold * initial_slope
                         dim_check = dydx[valid_slopes_idx] <= DIM_THRESH_PCT * init_slope
                         dim_indices = valid_slopes_idx[dim_check]
                         dim_idx = dim_indices[0] if dim_indices.size > 0 else len(grid_filtered) - 1
                    else:
                        dim_idx = len(grid_filtered) - 1 # If no positive slopes after the first, diminishing point is the end
                else:
                     dim_idx = len(grid_filtered) - 1 # If initial slope is zero or negative, diminishing point is the end


                fig = go.Figure(go.Scatter(x=grid_filtered, y=preds, mode='lines', name='Pred'))
                # Use grid_filtered indices for markers
                fig.add_trace(go.Scatter(x=[grid_filtered[mep_idx]], y=[preds[mep_idx]], mode='markers', marker=dict(color='blue', size=10), name='MEP'))
                fig.add_trace(go.Scatter(x=[grid_filtered[dim_idx]], y=[preds[dim_idx]], mode='markers', marker=dict(color='red', size=10), name='Diminishing'))
                if opt_idx > mep_idx and opt_idx < len(grid_filtered): # Only add optimal range if meaningful and indices are valid
                 fig.add_vrect(x0=grid_filtered[mep_idx], x1=grid_filtered[opt_idx], fillcolor="green", opacity=0.2, name='Optimal Range')
                fig.update_layout(title=f"Response Curve - {m}", xaxis_title=f"Transformed {m}", yaxis_title="Predicted Sales")
                st.plotly_chart(fig)
            else:
                 st.info(f"Skipping response curve for {m}: Predictions are constant or have no variation.")


    # Actual vs Predicted (AVP) chart
    st.write("##### Actual vs Predicted (AVP)")
    # Use the index from the full actual/predicted data for plotting
    plot_xaxis = df_features.index # Use original df_features index for dates

    fig_avp = go.Figure()
    fig_avp.add_trace(go.Scatter(x=plot_xaxis, y=y_full_actual, mode='lines+markers', name='Actual'))
    fig_avp.add_trace(go.Scatter(x=plot_xaxis, y=y_full_pred, mode='lines+markers', name='Predicted')) # Corrected x-axis

    # Find the date corresponding to the train/test split index
    train_n = len(y_train)
    if train_n < len(plot_xaxis):
         split_date = plot_xaxis[train_n] # Date of the first testing point
         fig_avp.add_vline(x=split_date, line=dict(color='red', dash='dash'), annotation_text='Train/Test Split')

    fig_avp.update_layout(title="Actual vs Predicted (AVP)", xaxis_title="Date", yaxis_title="Sales")
    st.plotly_chart(fig_avp)


# Wrap Scenario Analysis Module
def scenario_analysis_module():
    """
    Scenario analysis module, adapted for Streamlit
    """
    st.subheader("Scenario Analysis")

    # Retrieve model, data, and scaler from session state
    model = st.session_state.get('trained_model')
    feature_cols = st.session_state.get('feature_cols')
    X_test_scaled = st.session_state.get('X_test_scaled')
    X_test_original = st.session_state.get('X_test_original') # Need original test data for scenario changes
    scaler = st.session_state.get('scaler') # Need the fitted scaler
    df_features = st.session_state.get('df_features') # Need df_features for transformations
    X_train_original = st.session_state.get('X_train_original') # Need original train data for transformations

    if model is None or feature_cols is None or X_test_scaled is None or X_test_original is None or scaler is None or df_features is None or X_train_original is None:
        st.info("Please train the model first to run scenario analysis.")
        return

    st.write("##### Create a Scenario")
    st.write("Modify the variables in the sidebar to see the predicted impact on sales.")

    scenario_changes = {}

    # Use sidebar for scenario inputs
    st.sidebar.subheader("Scenario Inputs (% Change)")
    st.sidebar.write("Enter percentage change (e.g., 20 for +20%, -10 for -10%).")

    # Dynamically create number inputs for each feature in the sidebar
    if feature_cols:
        for col in feature_cols:
            # Use a unique key for each widget
            change_pct = st.sidebar.number_input(f"{col}:", value=0.0, step=1.0, format="%.1f", key=f"scenario_{col}_change")
            scenario_changes[col] = change_pct / 100.0 # Store as proportion


    if st.button("Run Scenario"):
        st.write("Running scenario...")
        try:
            # Use the original test data as the base for the scenario
            # Apply the same transformations (adstock, saturation) to the test data
            # before scaling and predicting.

            # Re-calculate adstock/saturation parameters on the full original data (train+test)
            # to ensure consistency with model training.
            # Or, fit adstock/saturation on the training data and apply to test data.
            # Let's use the parameters derived from the full df_features as done in plotting
            # This requires access to the full df_features, which should be in session_state

            # Recalculate param_store using the full df_features from session state
            param_store = {}
            ADSTOCK_DEFAULT_THETA = 0.4
            SAT_DEFAULT_BETA = 1e-6
            paid_keywords = ['paid','impr','impression','impressions','search','social','video','tv','display','spend','click','clicks','paid social']
            paid_media = [c for c in feature_cols if any(k in c.lower() for k in paid_keywords) and 'organic' not in c.lower()]

            df_features_full = st.session_state['df_features'] # Full df with FE
            for c in feature_cols:
                 if c in df_features_full.columns:
                     raw = df_features_full[c].fillna(0.0).astype(float).values
                     if c in paid_media:
                         theta = auto_theta(raw)
                         x_ad = adstock_geometric(raw, theta)
                         beta = auto_beta(x_ad)
                         scale = np.max(x_ad) if np.max(x_ad)>0 else 1.0
                         param_store[c] = {"theta":theta,"beta":beta,"scale":scale}
                     else:
                         param_store[c] = {"theta":None,"beta":None,"scale":1.0} # Store None for non-paid media

            # Apply transformations to the original test data based on param_store
            scenario_test_data_transformed = X_test_original.copy()
            for col in feature_cols:
                 if col in param_store:
                     raw_test = X_test_original[col].fillna(0.0).astype(float).values
                     theta = param_store[col]['theta']
                     beta = param_store[col]['beta']
                     scale = param_store[col]['scale']

                     # Apply adstock/saturation just to the test data section
                     # Need the historical context from training data for accurate adstock
                     # A proper implementation would require re-calculating adstock from the start
                     # up to the test period for the scenario.
                     # For simplicity here, we'll apply the transformation parameters to the test data in isolation,
                     # which is an approximation. A more complex approach needed for true adstock carryover.

                     # Simple approximation: apply transformation function to the test data series
                     # This is NOT ideal for adstock but ok for simple saturation/direct scaling
                     # A better way: Concatenate training data + test data (with scenario changes),
                     # apply adstock/saturation to the whole series, then slice the test part.

                     # Let's use the more accurate approach: concatenate train+test, apply transforms, slice test
                     X_train_original = st.session_state['X_train_original'][feature_cols] # Get train original features
                     full_original_data = pd.concat([X_train_original, X_test_original[feature_cols]])

                     # Apply scenario changes to the test portion of the full data
                     for var, change in scenario_changes.items():
                         if var in full_original_data.columns:
                              # Find the index of the test set start
                              test_start_idx = len(X_train_original)
                              full_original_data.loc[full_original_data.index[test_start_idx:], var] *= (1 + change)
                         else:
                              st.warning(f"Scenario variable '{var}' not found in full original data.")

                     # Apply transformations (adstock/saturation) to the *entire* series
                     full_transformed_data = pd.DataFrame(index=full_original_data.index)
                     for c in feature_cols:
                          if c in param_store and c in full_original_data.columns:
                              raw_full = full_original_data[c].fillna(0.0).astype(float).values
                              theta = param_store[c]['theta']
                              beta = param_store[c]['beta']
                              scale = param_store[c]['scale']

                              x_ad_full = adstock_geometric(raw_full, theta) if theta is not None else raw_full
                              x_sat_full = sat_1mexp(x_ad_full, beta) if beta is not None else x_ad_full
                              # Rescale using the scale factor derived from the full original data transformation step
                              # This assumes the scale factor was calculated based on the max of the full adstocked series
                              # Need to ensure param_store stores the correct scale (based on full data)
                              scaled_full = x_sat_full * (scale if scale is not None else 1.0)
                              full_transformed_data[c] = scaled_full
                          elif c in full_original_data.columns:
                               # Directly copy non-transformed columns
                               full_transformed_data[c] = full_original_data[c]
                          else:
                               st.warning(f"Column '{c}' not found in full original data during scenario transformation.")
                               full_transformed_data[c] = np.nan # Or handle missing column

                     # Slice the test portion after transformations
                     scenario_test_data_transformed = full_transformed_data.iloc[len(X_train_original):].copy()


            # Scale the scenario-transformed test data using the *same* scaler fitted on the training data
            try:
                # Align columns and fill NaNs before scaling
                scenario_test_data_aligned = scenario_test_data_transformed.reindex(columns=feature_cols, fill_value=0)
                if scenario_test_data_aligned.isnull().sum().sum() > 0:
                    st.warning("‚ö†Ô∏è  NaN values detected in scenario data before scaling. Filling with 0.")
                    scenario_test_data_aligned = scenario_test_data_aligned.fillna(0)

                scenario_data_scaled = scaler.transform(scenario_test_data_aligned)
                st.write("‚úÖ Scenario data scaled.")
            except Exception as e:
                st.error(f"‚ùå Error during scaling scenario data: {e}")
                return None


            # Predict new outcome
            try:
                if np.isnan(scenario_data_scaled).sum() > 0:
                     st.error("‚ùå NaN values detected in scaled scenario data before prediction.")
                     return None

                y_pred_scenario = model.predict(scenario_data_scaled)
                y_pred_scenario = np.clip(y_pred_scenario, 0, None)
                st.write("‚úÖ Scenario predictions generated (clipped at 0).")
            except Exception as e:
                 st.error(f"‚ùå Error during scenario prediction: {e}")
                 return None


            # Get baseline prediction on the test set (X_test_scaled is available in session state)
            y_base = model.predict(X_test_scaled)
            y_base = np.clip(y_base, 0, None)
            st.write("‚úÖ Baseline predictions generated (clipped at 0).")


            # Create a results DataFrame - Use the index from the original test set
            results_df = pd.DataFrame({
                'Baseline_Prediction': y_base,
                'Scenario_Prediction': y_pred_scenario
            }, index=X_test_original.index)


            # Calculate Lift (percentage change from baseline)
            results_df['Sales_Lift_Pct'] = np.nan
            valid_baseline_mask = (results_df['Baseline_Prediction'] != 0) & (~results_df['Baseline_Prediction'].isna())

            results_df.loc[valid_baseline_mask, 'Sales_Lift_Pct'] = (
                (results_df.loc[valid_baseline_mask, 'Scenario_Prediction'] - results_df.loc[valid_baseline_mask, 'Baseline_Prediction']) /
                results_df.loc[valid_baseline_mask, 'Baseline_Prediction'] * 100
            )

            st.write("\nüìä Scenario Analysis Results:")
            st.write("="*40)
            st.write(f"Total Baseline Sales: ‚Çπ{results_df['Baseline_Prediction'].sum():,.0f}")
            st.write(f"Total Scenario Sales: ‚Çπ{results_df['Scenario_Prediction'].sum():,.0f}")
            total_sales_lift = results_df['Scenario_Prediction'].sum() - results_df['Baseline_Prediction'].sum()
            st.write(f"Total Sales Lift: ‚Çπ{total_sales_lift:,.0f}")
            # Avoid division by zero if total_baseline_sales is 0
            total_baseline_sales = results_df['Baseline_Prediction'].sum()
            total_sales_lift_pct = (total_sales_lift / total_baseline_sales * 100) if total_baseline_sales != 0 else np.nan
            if not np.isnan(total_sales_lift_pct):
                st.write(f"Total Sales Lift Percentage: {total_sales_lift_pct:.2f}%")
            else:
                st.write("Total Sales Lift Percentage: N/A (Baseline Sales is 0)")

            st.write(f"Average Weekly Sales Lift Percentage: {results_df['Sales_Lift_Pct'].mean():.2f}%")


            st.write("üìã SCENARIO RESULTS DATAFRAME (first 5 rows):")
            st.dataframe(results_df.head())

            # Plot baseline vs scenario predictions
            plot_xaxis = results_df.index # Use the index of the results_df (which is the date index) for the x-axis
            fig_scenario = go.Figure()
            fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=results_df['Baseline_Prediction'], mode='lines+markers', name='Baseline Prediction'))
            fig_scenario.add_trace(go.Scatter(x=plot_xaxis, y=results_df['Scenario_Prediction'], mode='lines+markers', name='Scenario Prediction'))
            fig_scenario.update_layout(title="Baseline vs Scenario Predictions",
                                      xaxis_title="Date",
                                      yaxis_title="Predicted Sales")
            st.plotly_chart(fig_scenario)

        except Exception as e:
            st.error(f"‚ùå An error occurred during scenario execution: {str(e)}")


# --- Main Streamlit App Flow ---
def main():
    """
    Main function to run the Streamlit MMM application.
    """
    st.sidebar.header("File Upload")
    uploaded_file = st.sidebar.file_uploader("Upload your CSV file", type=["csv"])

    df = None
    if uploaded_file is not None:
        # Load and preprocess data
        # Pass the uploaded file object directly to the loading function
        df = load_and_preprocess_data(uploaded_file)
        st.session_state['original_data'] = df.copy() # Store original data

        st.subheader("Raw Data Preview")
        st.write(f"Shape: {df.shape}")
        st.dataframe(df.head())

        # Perform EDA (Optional - can be added as a separate section if needed)
        # st.subheader("Exploratory Data Analysis (EDA)")
        # Note: Comprehensive EDA plots might be too many for a basic Streamlit app.
        # Consider adding key EDA plots selectively or on demand.

        # Check if data loading was successful and has required columns
        if df is not None and 'Sales' in df.columns and 'Week_Ending' in df.columns:

            # Feature Engineering
            st.write("---") # Separator
            df_features = feature_engineering_module(df.copy())
            st.session_state['df_features'] = df_features.copy() # Store df with features

            # Define feature columns for modeling (exclude date and target)
            feature_cols = [col for col in df_features.columns if col not in ['Week_Ending', 'Sales'] and col is not None]

            if feature_cols:
                 # Model Preprocessing
                 st.write("---") # Separator
                 X_train_scaled, X_test_scaled, y_train, y_test, scaler = model_preprocessing(
                     df_features,
                     feature_cols,
                     target_column='Sales'
                 )

                 # Store preprocessing results in session state
                 st.session_state['feature_cols'] = feature_cols
                 st.session_state['X_train_scaled'] = X_train_scaled
                 st.session_state['X_test_scaled'] = X_test_scaled
                 st.session_state['y_train'] = y_train
                 st.session_state['y_test'] = y_test
                 st.session_state['scaler'] = scaler
                 # Store original train/test splits for scenario analysis base
                 # Ensure these are based on df_features, not the raw df
                 st.session_state['X_train_original'] = df_features[feature_cols].iloc[:len(y_train)].copy()
                 st.session_state['X_test_original'] = df_features[feature_cols].iloc[len(y_train):].copy()


                 # Model Selection and Training
                 st.write("---") # Separator
                 model_selection_and_training(X_train_scaled, y_train, X_test_scaled, y_test, feature_cols)

                 # Model Evaluation and Plotting (only run if model is trained AND splits are available)
                 if st.session_state.get('trained_model') is not None and 'X_train_original' in st.session_state and 'X_test_original' in st.session_state:
                      st.write("---") # Separator
                      model_evaluation_and_plotting()

                 # Scenario Analysis (only run if model is trained AND original data splits are available)
                 if st.session_state.get('trained_model') is not None and 'X_test_original' in st.session_state and 'X_train_original' in st.session_state:
                      st.write("---") # Separator
                      scenario_analysis_module()
                 elif st.session_state.get('trained_model') is not None:
                      st.warning("Scenario Analysis or Model Evaluation skipped: Original train/test data splits are missing.")


            else:
                 st.warning("No features available for modeling after preprocessing.")
        else:
            if uploaded_file is not None:
                 st.error("Uploaded file does not contain 'Sales' or 'Week_Ending' columns, or data loading failed.")

    else:
        st.info("Please upload a CSV file to get started.")

# Run the main function
if __name__ == "__main__":
    main()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# pandas
# numpy
# warnings
# datetime
# statsmodels
# sklearn
# plotly
# math
# difflib

with open('requirements.txt', 'r') as f:
    print(f.read())

"""# Task
Deploy a Streamlit application hosted on GitHub to Streamlit Sharing.

## Prepare your github repository

### Subtask:
Ensure your Streamlit application script (`.py` file) and any necessary data files are in a GitHub repository.

## Create a `requirements.txt` file

### Subtask:
Generate a `requirements.txt` file listing all the Python libraries used in your notebook.

**Reasoning**:
I have already created and updated the requirements.txt file in previous steps. I will now check the content of the file to ensure it is correct before concluding the subtask.
"""

with open('requirements.txt', 'r') as f:
    print(f.read())

"""## Sign up for streamlit sharing

### Subtask:
If you don't already have an account, sign up for Streamlit Sharing.

## Deploy your app

### Subtask:
Deploy your Streamlit application to Streamlit Sharing by connecting your GitHub repository.

## Summary:

### Data Analysis Key Findings

*   The Streamlit application script and necessary data files need to be in a GitHub repository.
*   A `requirements.txt` file containing all required Python libraries (`streamlit`, `pandas`, `numpy`, `warnings`, `datetime`, `statsmodels`, `sklearn`, `plotly`, `math`, and `difflib`) was created.
*   Signing up for Streamlit Sharing and deploying the application by connecting the GitHub repository are manual steps that need to be performed outside of the current environment on the Streamlit Sharing website.

### Insights or Next Steps

*   The user needs to manually perform the Git/GitHub operations, sign up for Streamlit Sharing, and deploy the app through the Streamlit Sharing website.
*   The provided `requirements.txt` file can be used for the deployment.
"""

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# streamlit
# pandas
# numpy
# statsmodels
# scikit-learn
# plotly